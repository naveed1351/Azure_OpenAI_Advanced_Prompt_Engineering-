{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chat with prompty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Install dependent packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting promptflow-devkit"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyopenssl 23.0.0 requires cryptography<40,>=38.0.0, but you have cryptography 44.0.2 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading promptflow_devkit-1.17.2-py3-none-any.whl (7.0 MB)\n",
            "     ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.3/7.0 MB 6.3 MB/s eta 0:00:02\n",
            "     --- ------------------------------------ 0.7/7.0 MB 8.7 MB/s eta 0:00:01\n",
            "     ---- ----------------------------------- 0.8/7.0 MB 8.8 MB/s eta 0:00:01\n",
            "     -------- ------------------------------- 1.5/7.0 MB 8.4 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 1.9/7.0 MB 8.0 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 2.1/7.0 MB 7.3 MB/s eta 0:00:01\n",
            "     --------------- ------------------------ 2.7/7.0 MB 8.5 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 3.2/7.0 MB 8.8 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 3.6/7.0 MB 8.9 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 4.0/7.0 MB 8.7 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 4.3/7.0 MB 8.8 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 4.7/7.0 MB 8.8 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 5.2/7.0 MB 9.0 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 5.6/7.0 MB 8.9 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 6.0/7.0 MB 9.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 6.5/7.0 MB 9.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  7.0/7.0 MB 9.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 7.0/7.0 MB 8.3 MB/s eta 0:00:00\n",
            "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21\n",
            "  Downloading azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl (154 kB)\n",
            "     ---------------------------------------- 0.0/154.1 kB ? eta -:--:--\n",
            "     -------------------------------------- 154.1/154.1 kB 4.6 MB/s eta 0:00:00\n",
            "Collecting pillow<11.1.0,>=10.1.0\n",
            "  Downloading pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
            "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "     ------- -------------------------------- 0.5/2.6 MB 9.8 MB/s eta 0:00:01\n",
            "     -------------- ------------------------- 0.9/2.6 MB 9.8 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 1.3/2.6 MB 9.4 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 1.8/2.6 MB 9.5 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 2.3/2.6 MB 9.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  2.6/2.6 MB 9.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.6/2.6 MB 9.1 MB/s eta 0:00:00\n",
            "Collecting keyring<25.0.0,>=24.2.0\n",
            "  Downloading keyring-24.3.1-py3-none-any.whl (38 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.32.0-py3-none-any.whl (17 kB)\n",
            "Collecting argcomplete>=3.2.3\n",
            "  Downloading argcomplete-3.6.2-py3-none-any.whl (43 kB)\n",
            "     ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 43.7/43.7 kB 2.1 MB/s eta 0:00:00\n",
            "Collecting sqlalchemy<3.0.0,>=1.4.48\n",
            "  Downloading sqlalchemy-2.0.40-cp310-cp310-win_amd64.whl (2.1 MB)\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     ------- -------------------------------- 0.4/2.1 MB 8.1 MB/s eta 0:00:01\n",
            "     --------------- ------------------------ 0.8/2.1 MB 8.7 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 1.2/2.1 MB 9.6 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 1.6/2.1 MB 9.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------  2.1/2.1 MB 9.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.1/2.1 MB 8.4 MB/s eta 0:00:00\n",
            "Collecting marshmallow<4.0.0,>=3.5\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Collecting filelock<4.0.0,>=3.4.0\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit) (307)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit) (0.4.6)\n",
            "Collecting pydash<8.0.0,>=6.0.0\n",
            "  Using cached pydash-7.0.7-py3-none-any.whl (110 kB)\n",
            "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit) (0.28.1)\n",
            "Collecting tabulate<1.0.0,>=0.9.0\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting flask-cors<6.0.0,>=5.0.0\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Collecting flask-restx<2.0.0,>=1.2.0\n",
            "  Using cached flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "Collecting strictyaml<2.0.0,>=1.5.0\n",
            "  Using cached strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit) (1.1.0)\n",
            "Collecting waitress<4.0.0,>=3.0.0\n",
            "  Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
            "     ---------------------------------------- 0.0/56.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 56.2/56.2 kB 3.1 MB/s eta 0:00:00\n",
            "Collecting promptflow-core<2.0.0,>=1.17.2\n",
            "  Downloading promptflow_core-1.17.2-py3-none-any.whl (987 kB)\n",
            "     ---------------------------------------- 0.0/987.9 kB ? eta -:--:--\n",
            "     ------------- ----------------------- 368.6/987.9 kB 11.2 MB/s eta 0:00:01\n",
            "     ----------------------------- -------- 778.2/987.9 kB 9.7 MB/s eta 0:00:01\n",
            "     -------------------------------------- 987.9/987.9 kB 8.9 MB/s eta 0:00:00\n",
            "Collecting pandas<3.0.0,>=1.5.3\n",
            "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
            "     ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.5/11.6 MB 10.2 MB/s eta 0:00:02\n",
            "     --- ------------------------------------ 1.0/11.6 MB 9.3 MB/s eta 0:00:02\n",
            "     ----- ---------------------------------- 1.5/11.6 MB 9.3 MB/s eta 0:00:02\n",
            "     ------ --------------------------------- 1.9/11.6 MB 9.4 MB/s eta 0:00:02\n",
            "     -------- ------------------------------- 2.3/11.6 MB 9.8 MB/s eta 0:00:01\n",
            "     --------- ------------------------------ 2.8/11.6 MB 9.3 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 3.2/11.6 MB 9.3 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 3.7/11.6 MB 9.5 MB/s eta 0:00:01\n",
            "     -------------- ------------------------- 4.2/11.6 MB 9.3 MB/s eta 0:00:01\n",
            "     ---------------- ----------------------- 4.7/11.6 MB 9.6 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 5.2/11.6 MB 9.5 MB/s eta 0:00:01\n",
            "     ------------------- -------------------- 5.7/11.6 MB 9.3 MB/s eta 0:00:01\n",
            "     --------------------- ------------------ 6.1/11.6 MB 9.5 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 6.5/11.6 MB 9.5 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 7.0/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ------------------------- -------------- 7.5/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 8.0/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 8.5/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 9.0/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 9.4/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 9.8/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 10.3/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 10.8/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 11.2/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  11.6/11.6 MB 9.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 11.6/11.6 MB 8.8 MB/s eta 0:00:00\n",
            "Collecting cryptography>=42.0.4\n",
            "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
            "     ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
            "     ----- ---------------------------------- 0.4/3.2 MB 8.9 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 0.8/3.2 MB 10.2 MB/s eta 0:00:01\n",
            "     --------------- ------------------------ 1.3/3.2 MB 10.0 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 1.7/3.2 MB 9.7 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 2.1/3.2 MB 9.1 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 2.6/3.2 MB 9.6 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 2.9/3.2 MB 9.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  3.2/3.2 MB 9.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 3.2/3.2 MB 8.2 MB/s eta 0:00:00\n",
            "Collecting gitpython<4.0.0,>=3.1.24\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "     ---------------------------------------- 0.0/207.6 kB ? eta -:--:--\n",
            "     -------------------------------------- 207.6/207.6 kB 6.4 MB/s eta 0:00:00\n",
            "Collecting azure-identity~=1.17\n",
            "  Downloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
            "     ---------------------------------------- 0.0/189.2 kB ? eta -:--:--\n",
            "     ------------------------------------- 189.2/189.2 kB 11.2 MB/s eta 0:00:00\n",
            "Collecting azure-core<2.0.0,>=1.28.0\n",
            "  Downloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
            "     ---------------------------------------- 0.0/207.1 kB ? eta -:--:--\n",
            "     -------------------------------------- 207.1/207.1 kB 6.3 MB/s eta 0:00:00\n",
            "Collecting msrest>=0.6.10\n",
            "  Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "Collecting opentelemetry-api~=1.26\n",
            "  Downloading opentelemetry_api-1.32.0-py3-none-any.whl (65 kB)\n",
            "     ---------------------------------------- 0.0/65.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 65.3/65.3 kB 3.4 MB/s eta 0:00:00\n",
            "Collecting opentelemetry-sdk~=1.26\n",
            "  Downloading opentelemetry_sdk-1.32.0-py3-none-any.whl (118 kB)\n",
            "     ---------------------------------------- 0.0/119.0 kB ? eta -:--:--\n",
            "     -------------------------------------- 119.0/119.0 kB 6.8 MB/s eta 0:00:00\n",
            "Collecting psutil<7,>=5.9\n",
            "  Downloading psutil-6.1.1-cp37-abi3-win_amd64.whl (254 kB)\n",
            "     ---------------------------------------- 0.0/254.4 kB ? eta -:--:--\n",
            "     -------------------------------------- 254.4/254.4 kB 7.9 MB/s eta 0:00:00\n",
            "Collecting fixedint==0.1.6\n",
            "  Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from cryptography>=42.0.4->promptflow-devkit) (1.15.1)\n",
            "Collecting Werkzeug>=0.7\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Collecting flask>=0.9\n",
            "  Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-10.0.0-py2.py3-none-any.whl (52 kB)\n",
            "     ---------------------------------------- 0.0/52.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 52.8/52.8 kB ? eta 0:00:00\n",
            "Collecting jsonschema\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "     ---------------------------------------- 0.0/88.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 88.5/88.5 kB 4.9 MB/s eta 0:00:00\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting pytz\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "     ---------------------------------------- 0.0/509.2 kB ? eta -:--:--\n",
            "     ------------------------------ ------ 419.8/509.2 kB 13.2 MB/s eta 0:00:01\n",
            "     ------------------------------------- 509.2/509.2 kB 10.6 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "     ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 62.8/62.8 kB 3.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: anyio in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit) (1.0.8)\n",
            "Requirement already satisfied: idna in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit) (3.4)\n",
            "Requirement already satisfied: certifi in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit) (2025.1.31)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit) (0.14.0)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting pywin32-ctypes>=0.2.0\n",
            "  Downloading pywin32_ctypes-0.2.3-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.11.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit) (8.6.1)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit) (23.0)\n",
            "Collecting googleapis-common-protos~=1.52\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "     ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
            "     -------------------------------------- 294.5/294.5 kB 9.2 MB/s eta 0:00:00\n",
            "Collecting deprecated>=1.2.6\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting opentelemetry-proto==1.32.0\n",
            "  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl (55 kB)\n",
            "     ---------------------------------------- 0.0/55.9 kB ? eta -:--:--\n",
            "     ---------------------------------------- 55.9/55.9 kB ? eta 0:00:00\n",
            "Requirement already satisfied: requests~=2.7 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit) (2.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl (18 kB)\n",
            "Collecting protobuf<6.0,>=5.0\n",
            "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
            "     ---------------------------------------- 0.0/434.5 kB ? eta -:--:--\n",
            "     -------------------------------------  430.1/434.5 kB 9.1 MB/s eta 0:00:01\n",
            "     -------------------------------------- 434.5/434.5 kB 6.8 MB/s eta 0:00:00\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "     ---------------------------------------- 0.0/347.8 kB ? eta -:--:--\n",
            "     ----------------------------------- - 337.9/347.8 kB 10.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- 347.8/347.8 kB 7.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit) (2.9.0.post0)\n",
            "Collecting docstring_parser\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Collecting filetype>=1.2.0\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting fastapi<1.0.0,>=0.109.0\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "     ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 95.2/95.2 kB 5.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (0.17.21)\n",
            "Collecting promptflow-tracing==1.17.2\n",
            "  Downloading promptflow_tracing-1.17.2-py3-none-any.whl (26 kB)\n",
            "Collecting tiktoken>=0.4.0\n",
            "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
            "     ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
            "     ---------------- -------------------- 399.4/894.0 kB 12.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- -- 839.7/894.0 kB 10.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- 894.0/894.0 kB 9.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: openai in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (1.73.0)\n",
            "Requirement already satisfied: typing-extensions!=4.6.0,>=3.10 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydash<8.0.0,>=6.0.0->promptflow-devkit) (4.8.0)\n",
            "Collecting greenlet>=1\n",
            "  Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit) (1.16.0)\n",
            "Collecting msal-extensions>=1.2.0\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Collecting msal>=1.30.0\n",
            "  Downloading msal-1.32.0-py3-none-any.whl (114 kB)\n",
            "     ---------------------------------------- 0.0/114.7 kB ? eta -:--:--\n",
            "     -------------------------------------- 114.7/114.7 kB 6.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pycparser in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from cffi>=1.12->cryptography>=42.0.4->promptflow-devkit) (2.21)\n",
            "Collecting wrapt<2,>=1.10\n",
            "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (2.11.3)\n",
            "Collecting starlette<0.47.0,>=0.40.0\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "     ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 72.0/72.0 kB 3.9 MB/s eta 0:00:00\n",
            "Collecting blinker>=1.9\n",
            "  Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting itsdangerous>=2.2\n",
            "  Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting click>=8.1.3\n",
            "  Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Collecting Jinja2>=3.1.2\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit) (3.21.0)\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.24.0-cp310-cp310-win_amd64.whl (234 kB)\n",
            "     ---------------------------------------- 0.0/234.6 kB ? eta -:--:--\n",
            "     -------------------------------------- 234.6/234.6 kB 7.2 MB/s eta 0:00:00\n",
            "Collecting referencing>=0.28.4\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Collecting attrs>=22.2.0\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b0\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl (188 kB)\n",
            "     ---------------------------------------- 0.0/188.4 kB ? eta -:--:--\n",
            "     -------------------------------------- 188.4/188.4 kB 5.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit) (1.26.15)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (0.2.6)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from anyio->httpx>=0.25.1->promptflow-devkit) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from anyio->httpx>=0.25.1->promptflow-devkit) (1.3.1)\n",
            "Collecting more-itertools\n",
            "  Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
            "     ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 63.0/63.0 kB 3.5 MB/s eta 0:00:00\n",
            "Collecting PyJWT[crypto]<3,>=1.0.0\n",
            "  Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (2.33.1)\n",
            "Collecting typing-extensions!=4.6.0,>=3.10\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "     ---------------------------------------- 0.0/45.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 45.8/45.8 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Collecting regex>=2022.1.18\n",
            "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
            "     ---------------------------------------- 0.0/274.0 kB ? eta -:--:--\n",
            "     ------------------------------------- 274.0/274.0 kB 16.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (0.9.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (4.65.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow-core<2.0.0,>=1.17.2->promptflow-devkit) (1.9.0)\n",
            "Installing collected packages: pytz, fixedint, filetype, aniso8601, wrapt, waitress, tzdata, typing-extensions, tabulate, smmap, rpds-py, regex, pywin32-ctypes, PyJWT, psutil, protobuf, pillow, oauthlib, more-itertools, marshmallow, MarkupSafe, itsdangerous, isodate, importlib-resources, greenlet, filelock, docstring_parser, click, blinker, attrs, argcomplete, Werkzeug, tiktoken, strictyaml, sqlalchemy, requests-oauthlib, referencing, pydash, pandas, opentelemetry-proto, Jinja2, jaraco.classes, googleapis-common-protos, gitdb, deprecated, cryptography, azure-core, starlette, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, msrest, keyring, jsonschema-specifications, gitpython, flask, opentelemetry-semantic-conventions, msal, jsonschema, flask-cors, fastapi, opentelemetry-sdk, msal-extensions, flask-restx, promptflow-tracing, opentelemetry-exporter-otlp-proto-http, azure-identity, promptflow-core, azure-monitor-opentelemetry-exporter, promptflow-devkit\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 39.0.1\n",
            "    Uninstalling cryptography-39.0.1:\n",
            "      Successfully uninstalled cryptography-39.0.1\n",
            "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 PyJWT-2.10.1 Werkzeug-3.1.3 aniso8601-10.0.0 argcomplete-3.6.2 attrs-25.3.0 azure-core-1.33.0 azure-identity-1.21.0 azure-monitor-opentelemetry-exporter-1.0.0b36 blinker-1.9.0 click-8.1.8 cryptography-44.0.2 deprecated-1.2.18 docstring_parser-0.16 fastapi-0.115.12 filelock-3.18.0 filetype-1.2.0 fixedint-0.1.6 flask-3.1.0 flask-cors-5.0.1 flask-restx-1.3.0 gitdb-4.0.12 gitpython-3.1.44 googleapis-common-protos-1.70.0 greenlet-3.1.1 importlib-resources-6.5.2 isodate-0.7.2 itsdangerous-2.2.0 jaraco.classes-3.4.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 keyring-24.3.1 marshmallow-3.26.1 more-itertools-10.6.0 msal-1.32.0 msal-extensions-1.3.1 msrest-0.7.1 oauthlib-3.2.2 opentelemetry-api-1.32.0 opentelemetry-exporter-otlp-proto-common-1.32.0 opentelemetry-exporter-otlp-proto-http-1.32.0 opentelemetry-proto-1.32.0 opentelemetry-sdk-1.32.0 opentelemetry-semantic-conventions-0.53b0 pandas-2.2.3 pillow-11.0.0 promptflow-core-1.17.2 promptflow-devkit-1.17.2 promptflow-tracing-1.17.2 protobuf-5.29.4 psutil-6.1.1 pydash-7.0.7 pytz-2025.2 pywin32-ctypes-0.2.3 referencing-0.36.2 regex-2024.11.6 requests-oauthlib-2.0.0 rpds-py-0.24.0 smmap-5.0.2 sqlalchemy-2.0.40 starlette-0.46.2 strictyaml-1.7.3 tabulate-0.9.0 tiktoken-0.9.0 typing-extensions-4.13.2 tzdata-2025.2 waitress-3.0.2 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install promptflow-devkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting promptflow\n",
            "  Downloading promptflow-1.17.2-py3-none-any.whl (19 kB)\n",
            "Collecting promptflow-tools\n",
            "  Downloading promptflow_tools-1.6.0-py3-none-any.whl (53 kB)\n",
            "     ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 53.6/53.6 kB 1.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: promptflow-tracing==1.17.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow) (1.17.2)\n",
            "Requirement already satisfied: promptflow-devkit==1.17.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow) (1.17.2)\n",
            "Requirement already satisfied: promptflow-core==1.17.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow) (1.17.2)\n",
            "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (0.115.12)\n",
            "Requirement already satisfied: filetype>=1.2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (1.2.0)\n",
            "Requirement already satisfied: flask<4.0.0,>=2.2.3 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (3.1.0)\n",
            "Requirement already satisfied: docstring_parser in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (0.16)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (2.9.0.post0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (4.23.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (6.1.1)\n",
            "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-core==1.17.2->promptflow) (0.17.21)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (2.0.40)\n",
            "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (0.28.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (0.4.6)\n",
            "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (5.0.1)\n",
            "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (24.3.1)\n",
            "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (1.7.3)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.5.3 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (2.2.3)\n",
            "Requirement already satisfied: cryptography>=42.0.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (44.0.2)\n",
            "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (7.0.7)\n",
            "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (3.0.2)\n",
            "Requirement already satisfied: argcomplete>=3.2.3 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (3.6.2)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (307)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (3.1.44)\n",
            "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (11.0.0)\n",
            "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (1.3.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (1.32.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (1.1.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (3.18.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (3.26.1)\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (0.9.0)\n",
            "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-devkit==1.17.2->promptflow) (1.0.0b36)\n",
            "Requirement already satisfied: openai in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow) (1.73.0)\n",
            "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow) (0.9.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow) (1.32.0)\n",
            "Collecting google-search-results==2.4.1\n",
            "  Using cached google_search_results-2.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from google-search-results==2.4.1->promptflow-tools) (2.29.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (4.9.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (4.13.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (1.3.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (0.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (1.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from openai->promptflow-tracing==1.17.2->promptflow) (2.11.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.17.2->promptflow) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.17.2->promptflow) (3.4)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (1.33.0)\n",
            "Requirement already satisfied: fixedint==0.1.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (0.1.6)\n",
            "Requirement already satisfied: opentelemetry-api~=1.26 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (1.32.0)\n",
            "Requirement already satisfied: azure-identity~=1.17 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (1.21.0)\n",
            "Requirement already satisfied: msrest>=0.6.10 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (0.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from cryptography>=42.0.4->promptflow-devkit==1.17.2->promptflow) (1.15.1)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.17.2->promptflow) (0.46.2)\n",
            "Requirement already satisfied: click>=8.1.3 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.17.2->promptflow) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.17.2->promptflow) (2.2.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.17.2->promptflow) (3.1.3)\n",
            "Requirement already satisfied: blinker>=1.9 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.17.2->promptflow) (1.9.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.17.2->promptflow) (3.1.6)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.17.2->promptflow) (6.5.2)\n",
            "Requirement already satisfied: pytz in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.17.2->promptflow) (2025.2)\n",
            "Requirement already satisfied: aniso8601>=0.82 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.17.2->promptflow) (10.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.17.2->promptflow) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit==1.17.2->promptflow) (1.0.8)\n",
            "Requirement already satisfied: certifi in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit==1.17.2->promptflow) (2025.1.31)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit==1.17.2->promptflow) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.17.2->promptflow) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.17.2->promptflow) (0.36.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.17.2->promptflow) (25.3.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.17.2->promptflow) (0.24.0)\n",
            "Requirement already satisfied: jaraco.classes in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.17.2->promptflow) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.11.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.17.2->promptflow) (8.6.1)\n",
            "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.17.2->promptflow) (0.2.3)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit==1.17.2->promptflow) (23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.17.2->promptflow) (1.32.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.17.2->promptflow) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.17.2->promptflow) (1.32.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.17.2->promptflow) (1.2.18)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-proto==1.32.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.17.2->promptflow) (5.29.4)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow) (0.53b0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.17.2->promptflow) (2.2.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.17.2->promptflow) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->promptflow-tracing==1.17.2->promptflow) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->promptflow-tracing==1.17.2->promptflow) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->promptflow-tracing==1.17.2->promptflow) (2.33.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1.0->promptflow-core==1.17.2->promptflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (2.0.4)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core==1.17.2->promptflow) (0.2.6)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit==1.17.2->promptflow) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from tiktoken>=0.4.0->promptflow-tracing==1.17.2->promptflow) (2024.11.6)\n",
            "Requirement already satisfied: msal>=1.30.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (1.32.0)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (1.3.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from cffi>=1.12->cryptography>=42.0.4->promptflow-devkit==1.17.2->promptflow) (2.21)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.17.2->promptflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.17.2->promptflow) (5.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.17.2->promptflow) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core==1.17.2->promptflow) (3.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (2.0.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (0.7.2)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.17.2->promptflow) (10.6.0)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from msal>=1.30.0->azure-identity~=1.17->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (2.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\t-nnazamy\\appdata\\local\\r-miniconda\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.17.2->promptflow) (3.2.2)\n",
            "Installing collected packages: google-search-results, promptflow, promptflow-tools\n",
            "Successfully installed google-search-results-2.4.1 promptflow-1.17.2 promptflow-tools-1.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install promptflow promptflow-tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prompty\n",
        "\n",
        "Prompty is a file with .prompty extension for developing prompt template. \n",
        "The prompty asset is a markdown file with a modified front matter. \n",
        "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724227192462
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "name: Chat Prompt\n",
            "description: A basic prompt that uses the chat API to answer questions with chat_history\n",
            "model:\n",
            "    api: chat\n",
            "    configuration:\n",
            "        type: azure_openai\n",
            "        connection: my_azure_open_ai_connection\n",
            "        azure_deployment: gpt-4-0125-Preview\n",
            "    parameters:\n",
            "        max_tokens: 256\n",
            "        temperature: 0.2\n",
            "\n",
            "inputs:\n",
            "    question:\n",
            "        type: string\n",
            "    chat_history:\n",
            "        type: list\n",
            "        default: []\n",
            "sample:\n",
            "    question: What is the meaning of life?\n",
            "    chat_history: []\n",
            "\n",
            "---\n",
            "system:\n",
            "You are an AI assistant who helps people find information.\n",
            "As the assistant, you answer questions briefly, succinctly, \n",
            "and in a personable manner using markdown and even add some personal flair with appropriate emojis.\n",
            "\n",
            "{% for item in chat_history %}\n",
            "{{item.role}}:\n",
            "{{item.content}}\n",
            "{% endfor %}\n",
            "\n",
            "user:\n",
            "{{question}}\n"
          ]
        }
      ],
      "source": [
        "with open(\"prompty/chat.prompty\") as fin:\n",
        "    print(fin.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create necessary connections\n",
        "Connection helps securely store and manage secret keys or other sensitive credentials required for interacting with LLM and other external tools for example Azure Content Safety.\n",
        "\n",
        "We need to set up the connection if we haven't added it before. After created, it's stored in local db and can be used in any flow.\n",
        "\n",
        "Prepare your Azure Open AI resource follow this [instruction](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) and get your `api_key` if you don't have one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#%pip install keyrings.alt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1724227198319
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auth_mode: key\n",
            "name: my_azure_open_ai_connection\n",
            "module: promptflow.connections\n",
            "created_date: '2024-07-04T01:25:55.056628'\n",
            "last_modified_date: '2024-08-21T07:59:58.201822'\n",
            "type: azure_open_ai\n",
            "api_key: '******'\n",
            "api_base: https://azuremlopenai.openai.azure.com/\n",
            "api_type: azure\n",
            "api_version: '2024-02-01'\n",
            "\n",
            "auth_mode: key\n",
            "name: my_azure_open_ai_connection\n",
            "module: promptflow.connections\n",
            "type: azure_open_ai\n",
            "api_key: '******'\n",
            "api_base: https://azuremlopenai.openai.azure.com/\n",
            "api_type: azure\n",
            "api_version: '2024-02-01'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from promptflow.client import PFClient\n",
        "from promptflow.connections import AzureOpenAIConnection, OpenAIConnection\n",
        "\n",
        "from promptflow.entities import AzureOpenAIConnection\n",
        "client = PFClient()\n",
        "# Initialize an AzureOpenAIConnection object\n",
        "connection = AzureOpenAIConnection(\n",
        "    name=\"my_azure_open_ai_connection\",\n",
        "    api_key=\"XXX\",\n",
        "    api_base=\"XXX\",\n",
        ")\n",
        "# Create the connection, note that api_key will be scrubbed in the returned result\n",
        "result = client.connections.create_or_update(connection)\n",
        "print(result)\n",
        "\n",
        "print(connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1724227207417
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using this connection : my_azure_open_ai_connection\n"
          ]
        }
      ],
      "source": [
        "conn_name = \"my_azure_open_ai_connection\"\n",
        "conn = client.connections.get(name=conn_name)\n",
        "print(\"using this connection :\",conn_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute prompty as function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1724227211381
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The capital of France is Paris!  It's not just the political capital but also a global center for art, fashion, gastronomy, and culture. A truly iconic city!\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from promptflow.core import Prompty\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\")\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can override connection with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1724227224344
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The capital of France is Paris! '"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
        "\n",
        "\n",
        "# override configuration with created connection in AzureOpenAIModelConfiguration\n",
        "configuration = AzureOpenAIModelConfiguration(\n",
        "    connection=\"my_azure_open_ai_connection\", azure_deployment=\"gpt-4o\"\n",
        ")\n",
        "\n",
        "# override openai connection with OpenAIModelConfiguration\n",
        "# configuration = OpenAIModelConfiguration(\n",
        "#     connection=connection,\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "\n",
        "override_model = {\n",
        "    \"configuration\": configuration,\n",
        "}\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\", model=override_model)\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize trace by using start_trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1724226907338
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt flow service has started...\n"
          ]
        }
      ],
      "source": [
        "from promptflow.tracing import start_trace\n",
        "\n",
        "# start a trace session, and print a url for user to check trace\n",
        "start_trace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Re-run below cell will collect a trace in trace UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1724226911351
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The capital of France is Paris! '"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You can view the trace detail from the following URL:\n",
            "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x73a5f4ff53faf77ee686f6a84d7556b4\n"
          ]
        }
      ],
      "source": [
        "# rerun the function, which will be recorded in the trace\n",
        "result = f(question=question)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eval the result \n",
        "\n",
        "In this example, we will use a prompt that determines whether a chat conversation contains an apology from the assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1724227565334
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "name: Apology Prompt\n",
            "description: A prompt that determines whether a chat conversation contains an apology from the assistant\n",
            "model:\n",
            "  api: chat\n",
            "  configuration:\n",
            "    type: azure_openai\n",
            "    connection: my_azure_open_ai_connection\n",
            "    azure_deployment: gpt-4o\n",
            "  parameters:\n",
            "    temperature: 0.2\n",
            "    response_format: { \"type\": \"json_object\" }\n",
            "inputs: \n",
            "  question:\n",
            "    type: string\n",
            "  answer:\n",
            "    type: string\n",
            "  messages:\n",
            "    type: list\n",
            "outputs:\n",
            "  apology:\n",
            "    type: string\n",
            "sample: ${file:sample.json}\n",
            "---\n",
            "\n",
            "system:\n",
            "You are an AI tool that determines if, in a chat conversation, the assistant apologized, like say sorry.\n",
            "Only provide a response of {\"apology\": 0} or {\"apology\": 1} so that the output is valid JSON.\n",
            "Give a apology of 1 if apologized in the chat conversation.\n",
            "\n",
            "Here are some examples of chat conversations and the correct response:\n",
            "\n",
            "**Example 1**\n",
            "user: Where can I get my car fixed?\n",
            "assistant: I'm sorry, I don't know that. Would you like me to look it up for you?\n",
            "result:\n",
            "{\"apology\": 1}\n",
            "\n",
            "**Here the actual conversation to be scored:**\n",
            "{% for message in messages %}\n",
            "{{ message.role }}: {{ message.content}}\n",
            "{% endfor %}\n",
            "user: {{question}}\n",
            "assistant: {{answer}}\n",
            "\n",
            "**result**\n"
          ]
        }
      ],
      "source": [
        "eval_prompty = \"prompty/apology.prompty\"\n",
        "\n",
        "with open(eval_prompty) as fin:\n",
        "    print(fin.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: the eval flow returns a `json_object`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1724227675353
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'apology': 0}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load prompty as a flow\n",
        "eval_flow = Prompty.load(eval_prompty)\n",
        "# execute the flow as function\n",
        "result = eval_flow(question=question, answer=result, messages=[])\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt flow service stop on 127.0.0.1:23333.\r\n"
          ]
        }
      ],
      "source": [
        "!pf service stop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Batch run with multi-line data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724228576093
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2024-08-21 08:22:47 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run prompty_20240821_082247_217704, log path: /home/azureuser/.promptflow/.runs/prompty_20240821_082247_217704/logs.txt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt flow service has started...\n",
            "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=prompty_20240821_082247_217704\n",
            "2024-08-21 08:22:55 +0000 3217081 execution.bulk     INFO     Process 3217104 terminated.\n",
            "2024-08-21 08:22:55 +0000 3217081 execution.bulk     WARNING  Process 3217120 had been terminated.\n",
            "2024-08-21 08:22:55 +0000 3217081 execution.bulk     WARNING  Process 3217109 had been terminated.\n",
            "2024-08-21 08:22:47 +0000 3217002 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
            "2024-08-21 08:22:47 +0000 3217002 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3}.\n",
            "2024-08-21 08:22:49 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(3217120)-Line number(0) start execution.\n",
            "2024-08-21 08:22:49 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(3217104)-Line number(1) start execution.\n",
            "2024-08-21 08:22:49 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(3217109)-Line number(2) start execution.\n",
            "2024-08-21 08:22:51 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:1)-Process id(3217104)-Line number(1) completed.\n",
            "2024-08-21 08:22:51 +0000 3217002 execution.bulk     INFO     Finished 1 / 3 lines.\n",
            "2024-08-21 08:22:51 +0000 3217002 execution.bulk     INFO     Average execution time for completed lines: 4.0 seconds. Estimated time for incomplete lines: 8.0 seconds.\n",
            "2024-08-21 08:22:52 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:2)-Process id(3217109)-Line number(2) completed.\n",
            "2024-08-21 08:22:52 +0000 3217002 execution.bulk     INFO     Finished 2 / 3 lines.\n",
            "2024-08-21 08:22:52 +0000 3217002 execution.bulk     INFO     Average execution time for completed lines: 2.5 seconds. Estimated time for incomplete lines: 2.5 seconds.\n",
            "2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     Process name(ForkProcess-2:3)-Process id(3217120)-Line number(0) completed.\n",
            "2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     Finished 3 / 3 lines.\n",
            "2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     Average execution time for completed lines: 2.34 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
            "2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     The thread monitoring the process [3217104-ForkProcess-2:1] will be terminated.\n",
            "2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     The thread monitoring the process [3217120-ForkProcess-2:3] will be terminated.\n",
            "2024-08-21 08:22:54 +0000 3217002 execution.bulk     INFO     The thread monitoring the process [3217109-ForkProcess-2:2] will be terminated.\n",
            "2024-08-21 08:22:54 +0000 3217104 execution.bulk     INFO     The process [3217104] has received a terminate signal.\n",
            "2024-08-21 08:22:54 +0000 3217120 execution.bulk     INFO     The process [3217120] has received a terminate signal.\n",
            "2024-08-21 08:22:54 +0000 3217109 execution.bulk     INFO     The process [3217109] has received a terminate signal.\n",
            "======= Run Summary =======\n",
            "\n",
            "Run name: \"prompty_20240821_082247_217704\"\n",
            "Run status: \"Completed\"\n",
            "Start time: \"2024-08-21 08:22:47.217538+00:00\"\n",
            "Duration: \"0:00:09.228898\"\n",
            "Output path: \"/home/azureuser/.promptflow/.runs/prompty_20240821_082247_217704\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from promptflow.client import PFClient\n",
        "\n",
        "flow = \"./prompty/chat.prompty\"  # path to the prompty file\n",
        "data = \"./prompty/data.jsonl\"  # path to the data file\n",
        "\n",
        "# create run with the flow and data\n",
        "pf = PFClient()\n",
        "base_run = pf.run(\n",
        "    flow=flow,\n",
        "    data=data,\n",
        "    column_mapping={\n",
        "        \"question\": \"${data.question}\",\n",
        "        \"chat_history\": \"${data.chat_history}\",\n",
        "    },\n",
        "    stream=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1724228583471
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>inputs.chat_history</th>\n",
              "      <th>inputs.line_number</th>\n",
              "      <th>outputs.output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's chat-GPT?</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>Chat-GPT is like a digital buddy that's super ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How many questions did I ask?</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>You've asked one question so far!  Got any mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Summarize our conversation?</td>\n",
              "      <td>[{'role': 'user', 'content': 'where is the nea...</td>\n",
              "      <td>2</td>\n",
              "      <td>Of course!  You asked about the nearest coffe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 inputs.question  \\\n",
              "0               What's chat-GPT?   \n",
              "1  How many questions did I ask?   \n",
              "2    Summarize our conversation?   \n",
              "\n",
              "                                 inputs.chat_history  inputs.line_number  \\\n",
              "0                                                 []                   0   \n",
              "1                                                 []                   1   \n",
              "2  [{'role': 'user', 'content': 'where is the nea...                   2   \n",
              "\n",
              "                                      outputs.output  \n",
              "0  Chat-GPT is like a digital buddy that's super ...  \n",
              "1  You've asked one question so far!  Got any mo...  \n",
              "2  Of course!  You asked about the nearest coffe...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "details = pf.get_details(base_run)\n",
        "details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1724228589908
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([\"Chat-GPT is like a digital buddy that's super good at chatting!  Developed by OpenAI, it's a type of AI (Artificial Intelligence) that's designed to have conversations with humans. Whether you need help with homework, want to know the weather, or just feel like chatting about your favorite TV show, Chat-GPT is there to keep the conversation going. It's based on a model called GPT (Generative Pre-trained Transformer), which is just a fancy way of saying it's really good at understanding and generating human-like text. So, it's like having a chat with a friend who knows a ton of stuff! \",\n",
              "       \"You've asked one question so far!  Got any more for me? \",\n",
              "       \"Of course!  You asked about the nearest coffee shop, but since I couldn't access your location, I couldn't provide a specific answer. Then, you inquired about Azure ML, and I briefly described it as a cloud-based platform for machine learning provided by Microsoft Azure. It's designed to help users build, train, and deploy machine learning models efficiently. Hope that helps!\"],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "details.head(3)['outputs.output'].values"
      ]
    }
  ],
  "metadata": {
    "build_doc": {
      "author": [
        "lalala123123@github.com",
        "wangchao1230@github.com"
      ],
      "category": "local",
      "section": "Prompty",
      "weight": 20
    },
    "description": "A quickstart tutorial to run a chat prompty and evaluate it.",
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "resources": "examples/requirements.txt, examples/prompty/chat-basic, examples/prompty/eval-apology"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
