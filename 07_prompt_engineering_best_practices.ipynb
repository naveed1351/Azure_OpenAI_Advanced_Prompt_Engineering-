{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720097684406
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"XXX\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"XXX\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "gather": {
          "logged": 1724377457848
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2025-01-01-preview\",\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1724376603988
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1. Understand the AOAI Models' capabilities. Start with the latest model, prove your idea , then test with smaller models. \n",
        "Model size is critical for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "** Length ** control (specify desired output length e.g.: number of words)\n",
        "\n",
        "** Tone ** control (e.g.: polite, passionate, professional, technical, funny, casual, serious etc.)\n",
        "\n",
        "** Style ** control (e.g.: in the style of Shakespeare, JK Rowling, Nelson Mandela etc.)\n",
        "\n",
        "** Audience ** control (e.g.: a 5-year-old can understand etc)\n",
        "\n",
        "** Context ** control (e.g.: news, novel, textbook, report, white paper, blog etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "gather": {
          "logged": 1724220799436
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \" Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on pensions.\"\n",
        "# Write a 2 paragraph inspiring poem about Iceland the food warehouse\n",
        "# Write a 2 paragraph inspiring poem focussing on products of Iceland the food warehouse in a funny way\n",
        "# Write a 2 paragraph inspiring poem focussing on products of Iceland the food warehouse in the style of Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "gather": {
          "logged": 1724220812307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Here's a simple and inspiring two-paragraph poem about pensions that a five-year-old could understand:\n",
            "\n",
            "---\n",
            "\n",
            "When you grow up, and work each day,  \n",
            "You save some pennies along the way.  \n",
            "Like planting seeds in a tiny pot,  \n",
            "They’ll grow and grow—don’t need a lot!  \n",
            "\n",
            "And when you're old, with hair of gray,  \n",
            "Your saved-up pennies will brighten your day.  \n",
            "They'll help you smile, relax, and rest,  \n",
            "Because you planned—and that's the best!  \n",
            "\n",
            "--- \n",
            "\n",
            "This poem simplifies the concept of pensions, making it relatable to a child by using imagery of saving pennies and planting seeds.\n"
          ]
        }
      ],
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. Put instructions at the begining of the prompt and use ### or \"\"\" to separate the instruction and context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "gather": {
          "logged": 1724220821426
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text = f\"\"\"\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\\\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \\\n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \\\n",
        "increasingly safe, useful, and powerful. \\n\\n \\\n",
        "In pursuit of our mission to ensure advanced AI benefits all of humanity, OpenAI remains a \\\n",
        "capped-profit company and is governed by the OpenAI non-profit. This structure allows us to \\\n",
        "raise the capital we need to fulfill our mission without sacrificing our core beliefs about \\\n",
        "broadly sharing benefits and the need to prioritize safety. \\\n",
        "Microsoft shares this vision and our values, and our partnership is instrumental to our progress.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "gather": {
          "logged": 1724220822459
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by hashtags as a bullet point list of the most important points.\n",
        "###{text}###\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1724220824323
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- OpenAI and Microsoft are extending their partnership with a multi-year, multi-billion dollar investment.  \n",
            "- This investment builds on Microsoft's previous investments in 2019 and 2021.  \n",
            "- The funding will support OpenAI's independent research and the development of safe, useful, and powerful AI.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=60\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 4. Articulate the desired output format through examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "gather": {
          "logged": 1724220830430
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "gather": {
          "logged": 1724220834461
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "user_message=f\"\"\"Extract the entities mentioned in the text below. \n",
        "First extract all company names, then extract all years, \n",
        "then extract specific topics which fit the content and finally extract general overarching themes\\n\\n \n",
        "Desired format: \n",
        "Company names: <comma_separated_list_of_company_names> \n",
        "Years: \n",
        "Specific topics:\n",
        "General themes: \n",
        "### Text:\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\\n \n",
        "###\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "gather": {
          "logged": 1724220843321
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Company names: OpenAI, Microsoft  \n",
            "Years: 2019, 2021  \n",
            "Specific topics: AI safety, AI research, AI development, partnership, investment  \n",
            "General themes: Artificial intelligence, technology collaboration, innovation, corporate investment  \n"
          ]
        }
      ],
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 5.Start with zero-shot, then few-shot (example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "gather": {
          "logged": 1724220850411
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "gather": {
          "logged": 1724220851415
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_zero=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "\n",
        "###Text: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords:###\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "gather": {
          "logged": 1724220854326
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI, Microsoft, partnership, multi-year, multi-billion dollar investment, 2019, 2021, independent research, AI, safe, useful, powerful.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_zero}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "gather": {
          "logged": 1724220856413
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_few=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "### Text 1: \n",
        "Stripe provides APIs that web developers can use to integrate \n",
        "payment processing into their websites and mobile applications. \\n\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites \n",
        "### \n",
        "\n",
        "###Text 2: \n",
        "OpenAI has trained cutting-edge language models that are very good at understanding \n",
        "and generating text. Our API provides access to these models and can be used to solve virtually \n",
        "any task that involves processing language. \\n\n",
        "Keywords 2: OpenAI, language models, text processing, API.\n",
        "### \n",
        "\n",
        "###Text 3: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords 3:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "gather": {
          "logged": 1724220858308
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI, Microsoft, partnership, investment, AI research, safe AI, useful AI, powerful AI.\n"
          ]
        }
      ],
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 6.Instead of just saying what not to do, say what to do instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "gather": {
          "logged": 1724220863425
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "system_message= f\"\"\"You are an agent trying to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. \n",
        "Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq \\n\\n\"\"\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"I can’t log in to my account.\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "gather": {
          "logged": 1724220873329
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you're unable to log into your account, there could be a few potential reasons for the issue. Here’s how you can troubleshoot:\n",
            "\n",
            "1. **Check Your Credentials**:\n",
            "   - Ensure that you're entering the correct email address or username (as applicable) and password.\n",
            "   - Verify that the Caps Lock key is not accidentally on, as passwords are case-sensitive.\n",
            "\n",
            "2. **Reset Your Password**:\n",
            "   - Use the \"Forgot Password\" option on the login page to reset your password. Instructions will be sent to your registered email address.\n",
            "\n",
            "3. **Clear Cache and Cookies**:\n",
            "   - Sometimes, browser cache or cookies can cause login issues. Clear them and try again.\n",
            "\n",
            "4. **Try a Different Browser or Device**:\n",
            "   - Logging in using a different web browser or device can help identify if the issue is device-specific.\n",
            "\n",
            "5. **Check for Account Lock or Suspension**:\n",
            "   - If you've attempted to log in multiple times with incorrect details, your account might be temporarily locked. Wait for a while before trying again.\n",
            "\n",
            "For more detailed guidance, refer to [this help article](www.samplewebsite.com/help/faq) and follow the instructions specific to login problems. If these steps don't resolve the issue, you may need to contact support directly for further assistance.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 7. Divide complex tasks into sub-tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1720098687167
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "gather": {
          "logged": 1724221069428
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text = f\"\"\"\n",
        "As an FSI company, we want our pension schemes to have a positive impact on our customers. Whether you're just starting to save into a pension or ready to take money out of it, we have the best interests of our members and customers at heart. It's about long-term financial wellbeing and sharing responsibility for building a better future. Save today to enjoy tomorrow.\"\"\"\n",
        "# example 1\n",
        "user_message = f\"\"\"\n",
        "Perform the actions below by separating your answers with line breaks. \n",
        "1 - Summarize the following text below with 1 sentence in English.\n",
        "2 - Translate the summary into Turkish.\n",
        "3 - List each company name in the Turkish summary.\n",
        "4 - Output a json object that contains the following:\n",
        "keys: turkish_summary, turkish_company_names.\n",
        "\n",
        "###\n",
        "Text:\n",
        "{text} \n",
        "###\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "gather": {
          "logged": 1724221072306
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 - The FSI company aims to provide positive impact on customers through their pension schemes. \n",
            "2 - FSI şirketi, müşterilerine emeklilik planları aracılığıyla pozitif etki sağlamayı hedefliyor.\n",
            "3 - FSI\n",
            "4 - {\n",
            "  \"turkish_summary\": \"FSI şirketi, müşterilerine emeklilik planları aracılığıyla pozitif etki sağlamayı hedefliyor.\",\n",
            "  \"turkish_company_names\": [\"FSI\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 8. Chain of Thought"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "The language model is prompted to generate a few intermediate reasoning steps to arrive at the final answer. \n",
        "\n",
        "Uses \"greedy decoding\" which means selecting the most likely token (word or character) at each step of the sequence generation process. At each time step, the model predicts the next token based on the previously generated tokens, and the token with the highest predicted probability is chosen as the output for that step. This process is repeated until the desired sequence length is reached or until a special end-of-sequence token is generated.\n",
        "\n",
        "**Temp=0** is used because it uses greedy decoding. It first creates the greedy coding and then the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "gather": {
          "logged": 1724221351442
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# This prompt gets wrong answer\n",
        "\n",
        "PROMPT_ZERO_SHOT = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: The answer (arabic numerals) is\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "gather": {
          "logged": 1724221352453
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Roger starts with 5 tennis balls. He buys 2 cans, each containing 3 tennis balls, so he gets \\( 2 \\times 3 = 6 \\) tennis balls from the cans. Adding these to the 5 he already has, he now has \\( 5 + 6 = 11 \\) tennis balls. After giving 4 to his friend, he is left with \\( 11 - 4 = 7 \\) tennis balls.\n",
            "\n",
            "The answer is **7\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_ZERO_SHOT}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "gather": {
          "logged": 1724221354423
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "PROMPT_ZERO_SHOT_CoT = \"\"\"Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "gather": {
          "logged": 1724221356305
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Let's break it down step by step:\n",
            "\n",
            "1. **Initial tennis balls Roger has**: 5 tennis balls.\n",
            "\n",
            "2. **Tennis balls from the cans**: Each can has 3 tennis balls, and Roger buys 2 cans.  \n",
            "   So, \\( 2 \\times 3 = 6 \\) tennis balls from the cans.\n",
            "\n",
            "3. **Total tennis balls Roger has after buying the cans**:  \n",
            "   \\( 5 + 6 = 11 \\) tennis balls.\n",
            "\n",
            "4. **Tennis balls Roger gives to his friend**: He gives away 4 tennis balls.  \n",
            "   \\( 11 - 4 = 7 \\).\n",
            "\n",
            "**Final Answer**: Roger has **7 tennis balls** now.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_ZERO_SHOT_CoT}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1724221989399
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_fsi_zeroshot_cot= \"\"\"Q: Let’s analyze the financial health of Company X. The company has a revenue of $10 million, expenses of $7 million, and a debt of $2 million. Calculate the net profit and the debt-to-equity ratio.\n",
        "A: The answer is\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1724221991308
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To calculate the net profit, you subtract the total expenses from the total revenue:\n",
            "\n",
            "Net Profit = Revenue - Expenses\n",
            "Net Profit = $10 million - $7 million\n",
            "Net Profit = $3 million\n",
            "\n",
            "Therefore, the net profit of Company X is $3 million.\n",
            "\n",
            "To calculate the debt-to-equity ratio, you divide the total debt by the total equity:\n",
            "\n",
            "Debt-to-Equity Ratio = Total Debt / Total Equity\n",
            "Debt-to-Equity Ratio = $2 million / ($\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_fsi_zeroshot_cot}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1724376683955
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_fsi_zeroshot_cot= \"\"\"Q: Let’s analyze the financial health of Company X. The company has a revenue of $10 million, expenses of $7 million, and a debt of $2 million. Calculate the net profit and the debt-to-equity ratio.\n",
        "A: Let's think step by step.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1724376688127
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, let's break it down step by step.\n",
            "\n",
            "1. Net Profit:\n",
            "Net Profit = Revenue - Expenses\n",
            "Net Profit = $10 million - $7 million\n",
            "Net Profit = $3 million\n",
            "\n",
            "2. Debt-to-Equity Ratio:\n",
            "Debt-to-Equity Ratio = Total Debt / Total Equity\n",
            "Total Equity = Total Assets - Total Debt\n",
            "Total Assets = Revenue\n",
            "Total Debt = $2 million\n",
            "\n",
            "Total Equity = $10 million - $2 million\n",
            "Total Equity = $8 million\n",
            "\n",
            "Debt-to-Equity Ratio = $2 million / $8 million\n",
            "Debt-to-Equity Ratio = 0.25\n",
            "\n",
            "Therefore, the net profit for Company X is $3 million and the debt-to-equity ratio is 0.25.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_fsi_zeroshot_cot}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "gather": {
          "logged": 1724222038404
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "PROMPT_FEW_SHOT_CoT = \"\"\"\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A: Elif had £10 at the beginning. When she consumed £2, 10-2=8 , £8 remains.\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "gather": {
          "logged": 1724222040301
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It seems like Roger started with 5 tennis balls, then bought 2 cans of tennis balls with 3 balls each, totaling 6 more balls. After giving 4 balls to his friend, he would have 5 + 6 - 4 = 7 tennis balls left.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_FEW_SHOT_CoT}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "** Auto-COT ** uses zero-shot-cot results just like few-shot learning for reasoning. Instead of using few-shot-cot, auto-cot can be useful and easy because you don't need to create manual examples (labels/reasonings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "gather": {
          "logged": 1724222044453
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_auto_cot = \"\"\"\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Lets think step by step.Roger had 5 tennis balls at the beginning. He bought 2 cans of tennis balls, each with 3 balls, so he now has 5+2x3=11 tennis balls. After giving 4 to his friend, he has 11-4=7 tennis balls remaining.\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "gather": {
          "logged": 1724222046311
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The response content is empty.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_auto_cot}\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Access the message content safely\n",
        "message_content = response.choices[0].message.content\n",
        "if message_content:\n",
        "    print(message_content.strip())\n",
        "else:\n",
        "    print(\"The response content is empty.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 9. Self Consistency\n",
        "\n",
        "Self-consistency aims \"to replace the naive greedy decoding used in chain-of-thought prompting\". The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to ** select the most consistent answer.**\n",
        "\n",
        "In the chat scenarios, **Asking the model to self-verify** its own responses. Like a student double-checking their answers, the AI model cross-references its responses to maintain consistency. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1724222059438
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I am 70 how old is my sister?\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If your sister was half your age when you were 6, that means she was 3 years\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=20,\n",
        "    stop=[\"\\nA:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1724222088434
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt2= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I am 70 how old is my sister? Let's think step by step\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, let's break it down step by step:\n",
            "\n",
            "1. When you were 6, your sister was half your age, which means she was 3 years old at that time (half of 6).\n",
            "\n",
            "2. The age difference between you and your sister is 3 years (6 - 3 = 3).\n",
            "\n",
            "3. Now that you are 70 years old, the age difference between you and your sister remains the same, which is 3 years.\n",
            "\n",
            "4. To find out your sister's current age, you can add the age difference to your current age. So, 70 + 3 = 73.\n",
            "\n",
            "Therefore, your sister is 73 years old now.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt2}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1724222112505
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt3=f\"\"\"\n",
        "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5\n",
        "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1724222502411
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    # Initialize the OpenAI client\n",
        "    #client = OpenAI(api_key='your-api-key')  # Replace with your actual API key\n",
        "\n",
        "    for i in range(num_times):\n",
        "        # Define the messages for the chat completion\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": start_phrase}\n",
        "        ]\n",
        "\n",
        "        # Send a chat completion request\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-35-turbo\",  # Use the appropriate model name\n",
        "            messages=messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens=100\n",
        "        )\n",
        "\n",
        "        # Extract and print the assistant's reply\n",
        "        reply = response.choices[0].message.content.strip()\n",
        "        print(f\"Response {i + 1}:\\n{reply}\")\n",
        "        print(\"*****************************\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "gather": {
          "logged": 1724222512293
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response 1:\n",
            "If you were 6 and your sister was half your age, your sister was 3 at that time. The age gap between you and your sister is constant, so when you are 70, your sister would be 70 - (6 - 3) = 67 years old.\n",
            "*****************************\n",
            "Response 2:\n",
            "If you were 6 and your sister was half your age, that means she was 3 years old at that time. The age gap between you and your sister is 3 years. Fast forward to now, as you are 70 years old, your sister would be 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 3:\n",
            "If you were 6 and your sister was half your age, she was 3 years old at that time. The age gap between you two is 3 years. So, as you are now 70 years old, your sister would be 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 4:\n",
            "If you were 6 years old and your sister was half your age, that means your sister was 3 years old at that time. Now, if you are 70 years old, your sister is 70 - (6 - 3) = 67 years old.\n",
            "*****************************\n",
            "Response 5:\n",
            "When you were 6, your sister was half your age, which means she was 3 years old. The age difference between you and your sister is always 3 years. So now that you are 70, your sister would be 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 6:\n",
            "When you were 6, your sister was half your age, which means she was 3 years old. The age difference between you and your sister is 3 years. Now that you are 70, your sister is 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 7:\n",
            "If when you were 6 years old, your sister was half your age, it means she was 3 years old at that time. The age gap between you two remains constant at 3 years. So now, if you are 70 years old, your sister would be 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 8:\n",
            "If you were 6 and your sister was half your age, your sister was 3 years old at that time. The age difference between you and your sister is 6 - 3 = 3 years. Since you are now 70, your sister must be 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 9:\n",
            "If when you were 6, your sister was half your age, it means she was 3 years old at that time. Since then, the age difference remains constant at 3 years. Therefore, now that you are 70, your sister would be 70 - 3 = 67 years old.\n",
            "*****************************\n",
            "Response 10:\n",
            "If you were 6 when your sister was half your age, that means your sister was 3 years old at that time. The age gap between you and your sister is 3 years, and it remains constant. So now that you are 70 years old, your sister would be 70 - 3 = 67 years old.\n",
            "*****************************\n"
          ]
        }
      ],
      "source": [
        "call_openai(10, prompt3, temperature = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 9. Step-Back Prompting Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "You start by providing the model with a prompt or question.\n",
        "The model generates a response based on the initial prompt.\n",
        "Instead of immediately accepting the response, you prompt the model to review or analyse its own response. This could involve asking the model to check for errors, verify facts, or consider alternative approaches.\n",
        "Based on the reassessment, the model generates a refined or corrected response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1724377472419
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# function to generate a response based on a prompt  \n",
        "def generate_response(prompt):  \n",
        "    messages = [  \n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  \n",
        "        {\"role\": \"user\", \"content\": prompt}  \n",
        "    ]  \n",
        "    response = client.chat.completions.create(  \n",
        "        model=\"gpt-4o\",  \n",
        "        messages=messages  \n",
        "    )  \n",
        "    return response.choices[0].message.content.strip()  \n",
        "\n",
        "# function to rephrase the input text  \n",
        "def rephrase_input(input_text):  \n",
        "    rephrase_prompt = (  \n",
        "        \"You are a helpful assistant. Please rephrase the following request to make it clearer and a more general question: \"  \n",
        "        f\"'{input_text}'\"  \n",
        "    )  \n",
        "    messages = [  \n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  \n",
        "        {\"role\": \"user\", \"content\": rephrase_prompt}  \n",
        "    ]  \n",
        "    response = client.chat.completions.create(  \n",
        "        model=\"gpt-4o\",  \n",
        "        messages=messages  \n",
        "    )  \n",
        "    return response.choices[0].message.content.strip()  \n",
        "  \n",
        "  \n",
        "# function to reword and check the answer  \n",
        "def reword_and_check_answer(original_answer):  \n",
        "    rewording_prompt = f\"Reword and verify the following statement: '{original_answer}'\"  \n",
        "    messages = [  \n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  \n",
        "        {\"role\": \"user\", \"content\": rewording_prompt}  \n",
        "    ]  \n",
        "    response = client.chat.completions.create(  \n",
        "        model=\"gpt-4o\",  \n",
        "        messages=messages  \n",
        "    )  \n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "gather": {
          "logged": 1724377593955
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Initial Response:\n",
            " That's correct! Iceland Foods Limited, commonly known as **Iceland**, is a British supermarket chain that specializes in frozen foods, including prepared meals, vegetables, and desserts. The retailer also offers non-frozen products, such as fresh produce, dairy, pantry staples, and beverages. It was founded in **1970** by **Malcolm Walker** and another business partner in Shropshire, England.\n",
            "\n",
            "Iceland is known for its value-oriented approach, targeting budget-conscious customers. Over the years, the chain has become one of the go-to supermarkets for frozen goods in the UK. It has also gained attention for its environmental and ethical initiatives, such as reducing plastic packaging and promoting sustainable fish sourcing. Iceland operates stores across the UK and internationally in some locations as well.\n",
            "\n",
            "Let me know if you'd like more details! 😊\n",
            "*** Reworded and Checked Answer:\n",
            " Here’s a reworded version of your statement, along with confirmation of its accuracy based on widely available knowledge:\n",
            "\n",
            "\"That's correct! Iceland Foods Limited, widely recognized as **Iceland**, is a British supermarket chain specializing in frozen foods, including prepared meals, vegetables, and desserts. The company also offers a range of non-frozen items, such as fresh produce, dairy products, pantry staples, and beverages. It was established in **1970** by **Malcolm Walker** and another business partner in Shropshire, England.\n",
            "\n",
            "Iceland is particularly known for its commitment to providing value, catering to budget-conscious shoppers. Over the years, it has become a popular choice for frozen goods in the UK. The retailer has also made headlines for its environmental and ethical efforts, such as initiatives to reduce plastic packaging and ensure sustainable fish sourcing. In addition to operating stores across the UK, Iceland has expanded internationally to certain locations.\n",
            "\n",
            "Would you like more information? 😊\"\n",
            "\n",
            "### Verification:\n",
            "The reworded statement is accurate, based on publicly available information about Iceland Foods Limited. Here are key details verified:\n",
            "- The company is widely referred to as Iceland.\n",
            "- It specializes in frozen foods but also sells non-frozen items.\n",
            "- Iceland was founded in 1970 by Malcolm Walker and another partner.\n",
            "- It has a reputation for providing affordable options and has a strong focus on frozen goods.\n",
            "- The chain has engaged in environmental initiatives, including reducing plastic packaging and promoting sustainability.\n",
            "- It operates stores in the UK and has some international presence.\n",
            "\n",
            "If you'd like to dive deeper into any specific aspect of Iceland Foods, let me know!\n",
            "*** Final Response:\n",
            " Here’s a reworded version of your statement, along with confirmation of its accuracy based on widely available knowledge:\n",
            "\n",
            "\"That's correct! Iceland Foods Limited, widely recognized as **Iceland**, is a British supermarket chain specializing in frozen foods, including prepared meals, vegetables, and desserts. The company also offers a range of non-frozen items, such as fresh produce, dairy products, pantry staples, and beverages. It was established in **1970** by **Malcolm Walker** and another business partner in Shropshire, England.\n",
            "\n",
            "Iceland is particularly known for its commitment to providing value, catering to budget-conscious shoppers. Over the years, it has become a popular choice for frozen goods in the UK. The retailer has also made headlines for its environmental and ethical efforts, such as initiatives to reduce plastic packaging and ensure sustainable fish sourcing. In addition to operating stores across the UK, Iceland has expanded internationally to certain locations.\n",
            "\n",
            "Would you like more information? 😊\"\n",
            "\n",
            "### Verification:\n",
            "The reworded statement is accurate, based on publicly available information about Iceland Foods Limited. Here are key details verified:\n",
            "- The company is widely referred to as Iceland.\n",
            "- It specializes in frozen foods but also sells non-frozen items.\n",
            "- Iceland was founded in 1970 by Malcolm Walker and another partner.\n",
            "- It has a reputation for providing affordable options and has a strong focus on frozen goods.\n",
            "- The chain has engaged in environmental initiatives, including reducing plastic packaging and promoting sustainability.\n",
            "- It operates stores in the UK and has some international presence.\n",
            "\n",
            "If you'd like to dive deeper into any specific aspect of Iceland Foods, let me know!\n"
          ]
        }
      ],
      "source": [
        "initial_prompt = \"Iceland Foods Limited, trading as Iceland, is a British supermarket chain.\"  \n",
        "  \n",
        "# Generate a response based on the initial prompt  \n",
        "response = generate_response(initial_prompt)  \n",
        "print(\"*** Initial Response:\\n\", response)  \n",
        "  \n",
        "# Reword and verify the answer  \n",
        "checked_response = reword_and_check_answer(response)  \n",
        "print(\"*** Reworded and Checked Answer:\\n\", checked_response)  \n",
        "  \n",
        "print(\"*** Final Response:\\n\", checked_response)  \n",
        "  \n",
        "# if __name__ == \"__main__\":  \n",
        "#     initial_prompt = input(\"Enter your question: \")  \n",
        "#     response = generate_response(initial_prompt)  \n",
        "#     print(\"Initial Response:\\n\", response)  \n",
        "#     checked_response = reword_and_check_answer(response)  \n",
        "#     print(\"Reworded and Checked Answer:\\n\", checked_response)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 10. Iterative approach\n",
        "\n",
        "Prompt engineering is an iterative process. If you're unsatisfied with the AI's response, refine your prompt and try again. Analyze the results you receive and consider adjusting your prompt's context, clarity, or structure. This process of trial and error will help you better understand how the AI model interprets your prompts and allow you to fine-tune your approach.\n",
        "\n",
        "·        Try different prompts to find what works best\n",
        "\n",
        "·        When attempting few-shot learning, try also to include direct instructions\n",
        "\n",
        "·        Rephrase a direct instruction set to be more or less concise, e.g.: taking a previous example and giving the next instruction without having to repeat the input\n",
        "\n",
        "·        Try different personas keywords to see how it affects the response style\n",
        "\n",
        "·        Use fewer or more examples in the few-shot learning\n",
        "\n",
        "·        Co-create with AI: An example of a very useful prompt to get a good output from the LLM :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "gather": {
          "logged": 1724222541409
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text=f\"\"\"\n",
        "Overall Results\n",
        "Year Ended December 31, 2023 versus 2022:\n",
        "Net income attributable to  ordinary shareholders was $1.1 billion for the year ended December 31, 2023, \n",
        "which compares to a net loss of $906 million from 2022, as a result of:\n",
        "• Favorable total investment returns recognized in net income of $1.1 billion for the year ended December 31, \n",
        "2023, consisting of the aggregate of net investment income, net realized (losses) gains, net unrealized gains \n",
        "(losses) and income (losses) from equity method investments, in comparison to negative total investment \n",
        "returns included in net income of $1.2 billion for the year ended December 31, 2022. The variance in total \n",
        "investment returns recognized in net income was driven by: \n",
        "◦ Net unrealized gains on our other investments, including equities of $397 million, in comparison to net \n",
        "unrealized losses in 2022 of $433 million, as a result of strong global equity market performance, \n",
        "particularly in the first and fourth quarters of 2023, and tightening high yield credit spreads, in comparison to \n",
        "the challenging market environment for the year ended December 31, 2022;\n",
        "◦ Net realized and unrealized gains on our fixed maturities of $66 million in 2023, compared to net realized \n",
        "and unrealized losses of $1.2 billion in 2022, primarily due to a decrease in interest rates across U.S., U.K. \n",
        "and European markets in 2023 as compared to significant increases in interest rates in 2022; \n",
        "◦ An increase in net investment income of $192 million in 2023 when compared to 2022, consistent with the \n",
        "increasing investment income we have earned on a sequential quarterly basis, primarily due to the \n",
        "reinvestment of fixed maturities at higher yields, deployment of consideration received from LPT and \n",
        "insurance transactions closed over the past 12 months and the impact of rising interest rates on our fixed \n",
        "maturities securities that are subject to floating interest rates; and\n",
        "◦ Income from equity method investments of $13 million, driven by income from our investments in Core \n",
        "Specialty and Citco, partially offset by losses from our investment in Monument Re, compared to losses of \n",
        "$74 million in 2022, primarily driven by losses from our investment in Monument Re. \n",
        "• An increase in other income of $241 million in 2023 when compared to 2022, largely driven by the first quarter \n",
        "2023 net gain recognized from the novation of the Enhanzed Re reinsurance of a closed block of life annuity \n",
        "policies; and \n",
        "• A favorable change in income tax benefit of $238 million, primarily driven by the establishment of a $205 million \n",
        "net deferred tax asset related to the enactment of the Bermuda Corporate Income Tax in December 2023. We \n",
        "also recorded a $25 million partial release of our deferred tax asset valuation allowance as a result of increases \n",
        "in projected taxable income in the U.S. and a reduction in deferred tax assets associated with decreases in \n",
        "unrealized losses on investment securities reported in AOCI in the U.S. and U.K. jurisdictions. This was partially \n",
        "offset by an increase in the valuation allowance in our U.K. and EU jurisdictions primarily due to losses, \n",
        "whereby no corresponding tax benefits were recognized for the period. \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1724222543421
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_iterative= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1724222556287
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here’s a simple explanation of the information provided:\n",
            "\n",
            "In 2023, the company made $1.1 billion in profit, while in 2022, it lost $906 million. This big improvement happened because:\n",
            "\n",
            "1. **Investments Did Better in 2023**:\n",
            "   - The company made money from investments (like stocks and bonds) instead of losing money like in 2022.\n",
            "   - Stock (equity) investments did well globally, especially early and late in 2023, leading to $397 million in gains, compared to a loss of $433 million in 2022.\n",
            "   - The company gained $66 million from bonds in 2023 because interest rates went down, while it lost $1.2 billion in 2022 when interest rates went up.\n",
            "   - Investment income (money earned from investments like interest and dividends) increased by $192 million. This happened because the company reinvested in higher-yield investments and benefited from higher interest rates on certain securities.\n",
            "\n",
            "2. **Profits From Partner Investments**: \n",
            "   - The company earned $13 million in 2023 from its investments in specific companies, compared to a loss of $74 million in 2022.\n",
            "\n",
            "3. **More Money From Other Sources**:\n",
            "   - The company earned $241 million more in 2023 thanks to a gain from a reinsurance deal in the first quarter.\n",
            "\n",
            "4. **Tax Benefits**:\n",
            "   - The company received $238 million in tax-related benefits in 2023. This included recognizing a $205 million future tax benefit due to new tax laws in Bermuda and some U.S. tax advantages. However, the company couldn’t use all its tax savings in some countries due to ongoing losses there.\n",
            "\n",
            "In short, the company turned things around in 2023 by earning money from its investments, benefiting from market improvements, and getting help from tax changes.\n"
          ]
        }
      ],
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Issue 1:** I want to keep numerical values in more readable output format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1724222590423
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_iterative1= f\"\"\" Your task is to organize given information in table format by keeping numarical values. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "gather": {
          "logged": 1724222601329
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the information organized into a table format:\n",
            "\n",
            "| **Category**                                                       | **2023**               | **2022**               | **Variance (2023 vs 2022)**                                                                              |\n",
            "|---------------------------------------------------------------------|------------------------|------------------------|--------------------------------------------------------------------------------------------------------|\n",
            "| **Net Income**                                                     | $1.1 billion          | $(906) million         | Favorable change of $2.006 billion                                                                     |\n",
            "| **Total Investment Returns in Net Income**                         | $1.1 billion          | $(1.2) billion         | Increase of $2.3 billion                                                                              |\n",
            "| **Net Unrealized Gains (Losses) on Other Investments**             | $397 million          | $(433) million         | Increase of $830 million (driven by strong global equity markets and favorable credit spreads)         |\n",
            "| **Net Realized and Unrealized Gains (Losses) on Fixed Maturities** | $66 million           | $(1.2) billion         | Increase of $1.266 billion (due to decreasing interest rates in 2023 vs significant increases in 2022) |\n",
            "| **Net Investment Income**                                          | $192 million          | -                      | Increase of $192 million (due to higher yields, investment deployment, and rising interest rates)      |\n",
            "| **Income (Loss) from Equity Method Investments**                   | $13 million           | $(74) million          | Increase of $87 million                                                                               |\n",
            "| **Other Income**                                                   | $241 million          | -                      | Increase of $241 million (driven by first quarter 2023 novation net gain)                              |\n",
            "| **Income Tax Benefit (Change)**                                    | $238 million favorable| -                      | Driven by $205 million deferred tax asset related to Bermuda Corporate Tax and $25 million valuation release |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative1}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Issue 2:** It is long so I need a brief summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "gather": {
          "logged": 1724222620386
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_iterative2= f\"\"\" \n",
        "Your task is to organize given information briefly in table format by keeping numarical values.\n",
        "\n",
        "Then, provide simple explanation by using at most 20 words.\n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "gather": {
          "logged": 1724222629339
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Organized Table:\n",
            "\n",
            "| Key Metric/Category                     | 2023 Value         | 2022 Value           | Change Explanation                                           |\n",
            "|-----------------------------------------|---------------------|----------------------|-------------------------------------------------------------|\n",
            "| **Net Income/(Loss)**                   | $1.1 billion        | ($906 million)       | Improved due to favorable investment returns and tax benefits. |\n",
            "| **Total Investment Returns**            | $1.1 billion        | ($1.2 billion)       | Shift from losses to gains due to equity and fixed maturity. |\n",
            "| - Net Unrealized Gains/Losses (Equities)| $397 million        | ($433 million)       | Driven by strong global equity markets and tightening spreads. |\n",
            "| - Realized/Unrealized Gains (Fixed)     | $66 million         | ($1.2 billion)       | Decrease in interest rates boosted fixed maturity performance. |\n",
            "| - Net Investment Income                 | $192 million (↑)    | N/A                  | Higher yields and reinvestment boosted income.              |\n",
            "| - Equity Method Investments Income/Loss | $13 million         | ($74 million)        | Improved by Core Specialty and Citco, offset partially by Monument Re. |\n",
            "| **Other Income**                        | $241 million (↑)    | N/A                  | Gain from novation of Enhanzed Re reinsurance contract.      |\n",
            "| **Income Tax Benefit**                  | $238 million (↑)    | N/A                  | Driven by deferred tax asset and partial valuation allowance release. |\n",
            "\n",
            "---\n",
            "\n",
            "### Explanation:\n",
            "2023 results improved due to strong investment gains, increased other income, and favorable tax adjustments compared to 2022 losses.\n"
          ]
        }
      ],
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative2}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "gather": {
          "logged": 1724222660465
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt_iterative3= f\"\"\" Your task is to organize given information briefly in table format by keeping numarical values.\n",
        "\n",
        "Then, provide simple explanation of the given context by using at most 20 words.\n",
        "\n",
        "Format everything as HTML that can be used in a website. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1724222674292
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```html\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "    <meta charset=\"UTF-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
            "    <title>Year-End Results</title>\n",
            "</head>\n",
            "<body>\n",
            "    <h1>Year-End Results: December 31, 2023 vs. December 31, 2022</h1>\n",
            "    <table border=\"1\" cellpadding=\"10\">\n",
            "        <thead>\n",
            "            <tr>\n",
            "                <th>Category</th>\n",
            "                <th>2023 ($ Millions)</th>\n",
            "                <th>2022 ($ Millions)</th>\n",
            "                <th>Change</th>\n",
            "            </tr>\n",
            "        </thead>\n",
            "        <tbody>\n",
            "            <tr>\n",
            "                <td>Net Income (Loss) Attributable to Shareholders</td>\n",
            "                <td>1,100</td>\n",
            "                <td>(906)</td>\n",
            "                <td>+2,006</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Net Investment Returns</td>\n",
            "                <td>1,100</td>\n",
            "                <td>(1,200)</td>\n",
            "                <td>+2,300</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Net Unrealized Gains/Losses on Equities</td>\n",
            "                <td>397</td>\n",
            "                <td>(433)</td>\n",
            "                <td>+830</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Net Gains/Losses on Fixed Maturities</td>\n",
            "                <td>66</td>\n",
            "                <td>(1,200)</td>\n",
            "                <td>+1,266</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Net Investment Income</td>\n",
            "                <td>192</td>\n",
            "                <td>0</td>\n",
            "                <td>+192</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Income/Loss from Equity Method Investments</td>\n",
            "                <td>13</td>\n",
            "                <td>(74)</td>\n",
            "                <td>+87</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Other Income</td>\n",
            "                <td>241</td>\n",
            "                <td>0</td>\n",
            "                <td>+241</td>\n",
            "            </tr>\n",
            "            <tr>\n",
            "                <td>Income Tax Benefit</td>\n",
            "                <td>238</td>\n",
            "                <td>0</td>\n",
            "                <td>+238</td>\n",
            "            </tr>\n",
            "        </tbody>\n",
            "    </table>\n",
            "    <p><strong>Simple Explanation:</strong> Net income improved significantly in 2023 due to strong investment returns, tax benefits, and gains from various sources.</p>\n",
            "</body>\n",
            "</html>\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative3}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Display the HTML content of the completion response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1724222704447
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "```html\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>Year-End Results</title>\n",
              "</head>\n",
              "<body>\n",
              "    <h1>Year-End Results: December 31, 2023 vs. December 31, 2022</h1>\n",
              "    <table border=\"1\" cellpadding=\"10\">\n",
              "        <thead>\n",
              "            <tr>\n",
              "                <th>Category</th>\n",
              "                <th>2023 ($ Millions)</th>\n",
              "                <th>2022 ($ Millions)</th>\n",
              "                <th>Change</th>\n",
              "            </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "            <tr>\n",
              "                <td>Net Income (Loss) Attributable to Shareholders</td>\n",
              "                <td>1,100</td>\n",
              "                <td>(906)</td>\n",
              "                <td>+2,006</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Net Investment Returns</td>\n",
              "                <td>1,100</td>\n",
              "                <td>(1,200)</td>\n",
              "                <td>+2,300</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Net Unrealized Gains/Losses on Equities</td>\n",
              "                <td>397</td>\n",
              "                <td>(433)</td>\n",
              "                <td>+830</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Net Gains/Losses on Fixed Maturities</td>\n",
              "                <td>66</td>\n",
              "                <td>(1,200)</td>\n",
              "                <td>+1,266</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Net Investment Income</td>\n",
              "                <td>192</td>\n",
              "                <td>0</td>\n",
              "                <td>+192</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Income/Loss from Equity Method Investments</td>\n",
              "                <td>13</td>\n",
              "                <td>(74)</td>\n",
              "                <td>+87</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Other Income</td>\n",
              "                <td>241</td>\n",
              "                <td>0</td>\n",
              "                <td>+241</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td>Income Tax Benefit</td>\n",
              "                <td>238</td>\n",
              "                <td>0</td>\n",
              "                <td>+238</td>\n",
              "            </tr>\n",
              "        </tbody>\n",
              "    </table>\n",
              "    <p><strong>Simple Explanation:</strong> Net income improved significantly in 2023 due to strong investment returns, tax benefits, and gains from various sources.</p>\n",
              "</body>\n",
              "</html>\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
