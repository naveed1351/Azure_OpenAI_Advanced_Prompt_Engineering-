{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-01\",#2023-07-01-preview\",#2024-02-15-preview\",#\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724375332436
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Test Function Calling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_function_call(messages, function_call = \"auto\"):\n",
        "    # Define the functions to use\n",
        "    functions = [\n",
        "        {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # Call the model with the user query (messages) and the functions defined in the functions parameter\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"gpt-4-0125-Preview\", # model = \"deployment_name\".\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=function_call)\n",
        "\n",
        "    return response.model_dump_json(indent=2)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724375959936
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_message = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}]\n",
        "# 'auto' : Let the model decide what function to call\n",
        "print(\"Let the model decide what function to call:\")\n",
        "print (get_function_call(first_message, \"auto\"))\n",
        "\n",
        "# 'none' : Don't call any function \n",
        "print(\"Don't call any function:\")\n",
        "print (get_function_call(first_message, \"none\"))\n",
        "\n",
        "# force a specific function call\n",
        "print(\"Force a specific function call:\")\n",
        "print (get_function_call(first_message, function_call={\"name\": \"get_current_weather\"}))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Let the model decide what function to call:\n{\n  \"id\": \"chatcmpl-9zDFR5IZvcGsVgAvLxQwqyFvTi3Pm\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"function_call\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": null,\n        \"refusal\": null,\n        \"role\": \"assistant\",\n        \"function_call\": {\n          \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\",\\\"unit\\\":\\\"fahrenheit\\\"}\",\n          \"name\": \"get_current_weather\"\n        },\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {}\n    }\n  ],\n  \"created\": 1724375961,\n  \"model\": \"gpt-4\",\n  \"object\": \"chat.completion\",\n  \"service_tier\": null,\n  \"system_fingerprint\": \"fp_e49e4201a9\",\n  \"usage\": {\n    \"completion_tokens\": 23,\n    \"prompt_tokens\": 83,\n    \"total_tokens\": 106\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"jailbreak\": {\n          \"filtered\": false,\n          \"detected\": false\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\nDon't call any function:\n{\n  \"id\": \"chatcmpl-9zDFSQrZ7kp6qYuzRpwy68x5dxIy2\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": \"To provide you with the current weather conditions in San Francisco, I'll need to check the latest data. Please give me a moment.\",\n        \"refusal\": null,\n        \"role\": \"assistant\",\n        \"function_call\": null,\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ],\n  \"created\": 1724375962,\n  \"model\": \"gpt-4\",\n  \"object\": \"chat.completion\",\n  \"service_tier\": null,\n  \"system_fingerprint\": \"fp_e49e4201a9\",\n  \"usage\": {\n    \"completion_tokens\": 27,\n    \"prompt_tokens\": 84,\n    \"total_tokens\": 111\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"jailbreak\": {\n          \"filtered\": false,\n          \"detected\": false\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\nForce a specific function call:\n{\n  \"id\": \"chatcmpl-9zDFThFFa2aM6Auu0mU6DMPdlhrKj\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"message\": {\n        \"content\": null,\n        \"refusal\": null,\n        \"role\": \"assistant\",\n        \"function_call\": {\n          \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\",\\\"unit\\\":\\\"fahrenheit\\\"}\",\n          \"name\": \"get_current_weather\"\n        },\n        \"tool_calls\": null\n      },\n      \"content_filter_results\": {}\n    }\n  ],\n  \"created\": 1724375963,\n  \"model\": \"gpt-4\",\n  \"object\": \"chat.completion\",\n  \"service_tier\": null,\n  \"system_fingerprint\": \"fp_e49e4201a9\",\n  \"usage\": {\n    \"completion_tokens\": 13,\n    \"prompt_tokens\": 93,\n    \"total_tokens\": 106\n  },\n  \"prompt_filter_results\": [\n    {\n      \"prompt_index\": 0,\n      \"content_filter_results\": {\n        \"hate\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"jailbreak\": {\n          \"filtered\": false,\n          \"detected\": false\n        },\n        \"self_harm\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"sexual\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        },\n        \"violence\": {\n          \"filtered\": false,\n          \"severity\": \"safe\"\n        }\n      }\n    }\n  ]\n}\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724375963904
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Functions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "def get_current_time(location):\n",
        "    try:\n",
        "        # Get the timezone for the city\n",
        "        timezone = pytz.timezone(location)\n",
        "\n",
        "        # Get the current time in the timezone\n",
        "        now = datetime.now(timezone)\n",
        "        current_time = now.strftime(\"%I:%M:%S %p\")\n",
        "\n",
        "        return current_time\n",
        "    except:\n",
        "        return \"Sorry, I couldn't find the timezone for that location.\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229471663
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_current_time(\"America/New_York\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "'04:37:52 AM'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229471781
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Call a Function using AOAI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Describe the functions so that the model knows how to call them"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "        {\n",
        "            \"name\": \"get_current_time\",\n",
        "            \"description\": \"Get the current time in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The location name. The pytz is used to get the timezone for that location. Location names should be in a format like America/New_York, Asia/Bangkok, Europe/London\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "\n",
        "available_functions = {\n",
        "            \"get_current_time\": get_current_time\n",
        "        } "
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229477642
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Define a helper function to validate the function call"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "# helper method used to check if the correct arguments are provided to a function\n",
        "def check_args(function, args):\n",
        "    sig = inspect.signature(function)\n",
        "    params = sig.parameters\n",
        "\n",
        "    # Check if there are extra arguments\n",
        "    for name in args:\n",
        "        if name not in params:\n",
        "            return False\n",
        "    # Check if the required arguments are provided \n",
        "    for name, param in params.items():\n",
        "        if param.default is param.empty and name not in args:\n",
        "            return False\n",
        "\n",
        "    return True"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229479644
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229480225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_message = [{\"role\": \"user\", \"content\": \"What time is it in New York?\"}] #Added this line after you cloned the repo"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229481662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4-0125-Preview\", # model = \"deployment_name\".\n",
        "    messages=first_message,\n",
        "    functions=functions,\n",
        "    function_call=\"auto\")\n",
        "\n",
        "\n",
        "response_message = response.choices[0].message\n",
        "print(response_message)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"America/New_York\"}', name='get_current_time'), tool_calls=None)\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229483599
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_conversation(messages, functions, available_functions, deployment_id):\n",
        "    # Step 1: send the conversation and available functions to GPT\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"gpt-4-0125-Preview\", # model = \"deployment_name\".\n",
        "    messages=messages,\n",
        "    functions=functions,\n",
        "    function_call=\"auto\")\n",
        "\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "\n",
        "\n",
        "    # Step 2: check if GPT wanted to call a function\n",
        "    if response_message.function_call:\n",
        "        print(\"Recommended Function call:\")\n",
        "        print(response_message.function_call)\n",
        "        print()\n",
        "        \n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        \n",
        "        function_name = response_message.function_call.name\n",
        "        \n",
        "        # verify function exists\n",
        "        if function_name not in available_functions:\n",
        "            return \"Function \" + function_name + \" does not exist\"\n",
        "        function_to_call = available_functions[function_name]  \n",
        "        \n",
        "        # verify function has correct number of arguments\n",
        "        function_args = json.loads(response_message.function_call.arguments)\n",
        "        if check_args(function_to_call, function_args) is False:\n",
        "            return \"Invalid number of arguments for function: \" + function_name\n",
        "        function_response = function_to_call(**function_args)\n",
        "        \n",
        "        print(\"Output of function call:\")\n",
        "        print(function_response)\n",
        "        print()\n",
        "        \n",
        "        # Step 4: send the info on the function call and function response to GPT\n",
        "        \n",
        "        # adding assistant response to messages\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": response_message.role,\n",
        "                \"name\": response_message.function_call.name,\n",
        "                \"content\": response_message.function_call.arguments,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # adding function response to messages\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "\n",
        "        print(\"Messages in second request:\")\n",
        "        for message in messages:\n",
        "            print(message)\n",
        "        print()\n",
        "\n",
        "        # get a new response from GPT where it can see the function response\n",
        "        second_response = client.chat.completions.create(\n",
        "        model=\"gpt-4-0125-Preview\", # model = \"deployment_name\".\n",
        "        messages=messages,\n",
        "        )\n",
        "        return second_response.choices[0].message.content"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229483704
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What time is it in New York?\"}]\n",
        "assistant_response = run_conversation(messages, functions, available_functions, \"gpt-4-32k\")\n",
        "print(assistant_response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recommended Function call:\nFunctionCall(arguments='{\"location\":\"America/New_York\"}', name='get_current_time')\n\nOutput of function call:\n04:38:06 AM\n\nMessages in second request:\n{'role': 'user', 'content': 'What time is it in New York?'}\n{'role': 'assistant', 'name': 'get_current_time', 'content': '{\"location\":\"America/New_York\"}'}\n{'role': 'function', 'name': 'get_current_time', 'content': '04:38:06 AM'}\n\nIt is currently 04:38 AM in New York.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724229487645
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}