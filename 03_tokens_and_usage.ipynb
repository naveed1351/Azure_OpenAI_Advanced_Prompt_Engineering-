{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Key topics:\n",
        "\n",
        "**Tokens**: Tokens are a numerical representation of how the Azure OpenAI models process text. So they are representing words or just chunks of characters. For English text, 1 token is approximately 4 characters or 0.75 words. \n",
        "\n",
        "**Tokenization**: splitting input/output texts into smaller units for LLMs.\n",
        "\n",
        "**Vocabulary size**: the number of tokens each model uses, which varies among different GPT models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1724161825987
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of tokens: 18\n",
            "Tokens :  ['Microsoft', \"'s\", ' mission', ' is', ' to', ' empower', ' every', ' person', ' and', ' every', ' organization', ' on', ' the', ' planet', ' to', ' achieve', ' more', '.']\n",
            "Tokens' numerical values: [13068, 596, 9131, 374, 311, 26285, 1475, 1732, 323, 1475, 7471, 389, 279, 11841, 311, 11322, 810, 13]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken #python library for encoding text \n",
        "\n",
        "cl100k_base = tiktoken.get_encoding(\"cl100k_base\") #pretrained tokenizer\n",
        "\n",
        "enc = tiktoken.Encoding( \n",
        "    name=\"gpt-4o\",  \n",
        "    pat_str=cl100k_base._pat_str, \n",
        "    mergeable_ranks=cl100k_base._mergeable_ranks, \n",
        "    special_tokens={ \n",
        "        **cl100k_base._special_tokens, \n",
        "        \"<|im_start|>\": 100264, \n",
        "        \"<|im_end|>\": 100265\n",
        "    } \n",
        ") \n",
        "\n",
        "tokens = enc.encode( \n",
        "    \"Microsoft's mission is to empower every person and every organization on the planet to achieve more.\" #tbc\n",
        ") \n",
        "\n",
        "print('Total number of tokens:', len(tokens))\n",
        "print('Tokens : ', [enc.decode([t]) for t in tokens])\n",
        "print(\"Tokens' numerical values:\", tokens)\n",
        "\n",
        "#https://platform.openai.com/tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1724161441022
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Returns the num of tokens used on a string\n",
        "def num_tokens_from_string(string: str) -> int:\n",
        "    encoding_name ='cl100k_base'\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1724161848022
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_tokens_from_string(\"Microsoft's mission is to empower every person and every organization on the planet to achieve more.\")#tbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "    api_version=\"2025-01-01-preview\", #latest GA API version: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_name='gpt-4o'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1724165142902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1724165206142
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#import openai\n",
        "#print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending a test completion job\n",
            "Microsoft's mission is **\"to empower every person and every organization on the planet to achieve more.\"** \n",
            "\n",
            "This mission reflects Microsoft's focus on enabling individuals and organizations through their technology, tools, and services, helping them achieve their goals and maximize their potential. It highlights inclusivity, scalability, and an emphasis on technology as a means for global empowerment.\n"
          ]
        }
      ],
      "source": [
        "print('Sending a test completion job')\n",
        "\n",
        "start_phrase = \"Microsoft's mission is to \"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": start_phrase}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=deployment_name,\n",
        "    messages=messages,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "# Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1724165386982
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-BZd78ZpCqcBEHaeVdLDlD3djhsNav', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Microsoft\\'s mission is **\"to empower every person and every organization on the planet to achieve more.\"** \\n\\nThis mission reflects Microsoft\\'s focus on enabling individuals and organizations through their technology, tools, and services, helping them achieve their goals and maximize their potential. It highlights inclusivity, scalability, and an emphasis on technology as a means for global empowerment.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1747831534, model='gpt-4o-2024-11-20', object='chat.completion', service_tier=None, system_fingerprint='fp_ee1d74bde0', usage=CompletionUsage(completion_tokens=71, prompt_tokens=13, total_tokens=84, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1724165395967
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletionUsage(completion_tokens=71, prompt_tokens=13, total_tokens=84, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Azure OpenAI uses a subword tokenization method called \"Byte-Pair Encoding (BPE)\" for its GPT-based models. ** BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token **, until a certain number of tokens or a vocabulary size is reached. BPE can help the model to handle rare or unseen words, and to create more compact and consistent representations of the texts. BPE can also allow the model to generate new words or tokens, by combining existing ones. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
