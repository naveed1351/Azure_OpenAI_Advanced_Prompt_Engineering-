{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
      "metadata": {},
      "source": [
        "## Set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041de095",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
      "metadata": {
        "gather": {
          "logged": 1724229561634
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from typing import List\n",
        "from operator import itemgetter\n",
        "\n",
        "# LangChain Imports needed\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "#from langchain_core.documents import Document\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "\n",
        "# Our own libraries needed\n",
        "#from common.prompts import DOCSEARCH_PROMPT\n",
        "#from common.utils import get_search_results\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
      "metadata": {
        "gather": {
          "logged": 1724229561786
        }
      },
      "outputs": [],
      "source": [
        "QUESTION = \"what is azure ml for\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
      "metadata": {
        "gather": {
          "logged": 1724229561921
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb",
      "metadata": {},
      "source": [
        "## A gentle intro to chaining LLMs and prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69",
      "metadata": {},
      "source": [
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step.\n",
        "\n",
        "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
        "\n",
        "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
        "\n",
        "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
        "\n",
        "Here’s an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "13df9247-e784-4e04-9475-55e672efea47",
      "metadata": {
        "gather": {
          "logged": 1724229566372
        }
      },
      "outputs": [],
      "source": [
        "COMPLETION_TOKENS = 2000\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", \n",
        "                      temperature=0.5, \n",
        "                      max_tokens=COMPLETION_TOKENS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a3b55adb-6f98-4f15-b67a-9fbba5820560",
      "metadata": {
        "gather": {
          "logged": 1724229567664
        }
      },
      "outputs": [],
      "source": [
        "output_parser = StrOutputParser()\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
        "    (\"user\", \"{input}. Give your response in {language}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6417d052-0035-4635-93e8-2bd3ec50d796",
      "metadata": {},
      "source": [
        "The | symbol is similar to a unix pipe operator, which chains together the different components feeds the output from one component as input into the next component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "77a37e60-a1ef-4750-a1ec-9e4fe5ba07fa",
      "metadata": {
        "gather": {
          "logged": 1724229569672
        }
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "50ea1a39-bea2-4f18-bcc0-bd4eb2e01675",
      "metadata": {
        "gather": {
          "logged": 1724229583840
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Azure Machine Learning (Azure ML) es un servicio en la nube de Microsoft diseñado para facilitar la creación, el entrenamiento, la implementación y la gestión de modelos de aprendizaje automático (machine learning) a escala. Su propósito principal es ayudar a los desarrolladores, científicos de datos y equipos de TI a aprovechar el poder del aprendizaje automático para resolver problemas complejos, automatizar procesos y tomar decisiones basadas en datos.\\n\\n### Principales usos de Azure ML:\\n1. **Desarrollo de modelos de aprendizaje automático**: Permite a los usuarios crear modelos personalizados utilizando lenguajes como Python o R, y bibliotecas populares como TensorFlow, PyTorch, y Scikit-learn.\\n   \\n2. **Entrenamiento de modelos**: Ofrece recursos de computación escalables para entrenar modelos de manera eficiente, ya sea en máquinas locales, en clústeres en la nube o incluso utilizando GPUs y TPUs.\\n\\n3. **Implementación de modelos**: Facilita la implementación de modelos como servicios web en la nube, lo que permite integrarlos fácilmente en aplicaciones o sistemas existentes.\\n\\n4. **Automatización del aprendizaje automático (AutoML)**: Azure ML incluye herramientas para automatizar partes del proceso de creación de modelos, como la selección de características, el ajuste de hiperparámetros y la elección de algoritmos.\\n\\n5. **Gestión del ciclo de vida de los modelos**: Proporciona herramientas para rastrear experimentos, registrar modelos, monitorear su desempeño y actualizar modelos en producción.\\n\\n6. **Colaboración y escalabilidad**: Permite a los equipos colaborar en proyectos de machine learning utilizando espacios de trabajo compartidos y aprovechar la infraestructura en la nube para escalar según sea necesario.\\n\\n7. **Integración con otras herramientas y servicios**: Azure ML se integra fácilmente con otros servicios de Azure, como Azure Data Factory, Azure Databricks y Azure Synapse Analytics, así como con herramientas de código abierto.\\n\\nEn resumen, Azure ML es una plataforma poderosa y flexible que permite a las organizaciones implementar soluciones de inteligencia artificial y aprendizaje automático de manera más rápida y eficiente, optimizando el uso de recursos y mejorando la toma de decisiones basada en datos.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"input\": QUESTION, \"language\": \"Spanish\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5",
      "metadata": {},
      "source": [
        "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
        "\n",
        "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2",
      "metadata": {
        "tags": []
      },
      "source": [
        "**The second type of Chains are Utility:**\n",
        "\n",
        "* Utility — These are specialized chains, comprised of many building blocks to help solve a specific task. For example, LangChain supports some end-to-end chains (such as `create_retrieval_chain` for QnA Doc retrieval, Summarization, etc).\n",
        "\n",
        "We will build our own specific chain in this workshop for digging deeper and solve our use case of enhancing the results of Azure AI Search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e79235-3d8b-4713-9336-5004cc4a1556",
      "metadata": {},
      "source": [
        "So really, our only job now is to make sure that the results from the Azure AI Search queries fit on the LLM context size, and then let it do its magic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235d4238-df6e-40eb-ab38-4fe6db614acd",
      "metadata": {},
      "source": [
        "Now let's create a Prompt Template that will ground the response only in the given context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f86ed786-aca0-4e25-947b-d9cf3a82665c",
      "metadata": {
        "gather": {
          "logged": 1724229587824
        }
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based **ONLY** on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "If the question is different from the context, just tell \"sorry,I can not assist with this query\"\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "919edc42-2c25-4407-84d3-e9e86046801e",
      "metadata": {
        "gather": {
          "logged": 1724229593680
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based **ONLY** on the following context:\\n{context}\\n\\nQuestion: {question}\\nIf the question is different from the context, just tell \"sorry,I can not assist with this query\"\\n'), additional_kwargs={})])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "25cba3d1-b5ab-4e28-96b3-ef923d99dc9f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 15.6 ms\n",
            "Wall time: 471 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'sorry, I can not assist with this query'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time \n",
        "# Creation of our custom chain\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"question\": \"Tell me about Nationwide Building Society\", \"context\": \"Azure Machine LEarning is E2E ML platform.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b94b8f-ea6f-40ee-afd9-2400ac6d5208",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#  Internet and Websites Search using Bing API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc7d9da",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e57aae",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b720627",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2ab1a2a",
      "metadata": {},
      "source": [
        "- Note: Make sure you update your Bing Search URL and Key in the Credentials.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dceab3d9-5a9e-42cb-bc95-68b85c10f1ef",
      "metadata": {
        "gather": {
          "logged": 1724229619613
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from typing import Dict, List, Optional, Type\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_community.utilities import BingSearchAPIWrapper\n",
        "\n",
        "\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import BINGSEARCH_PROMPT\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2f7c618e-5d5d-4c6d-8fcc-9debf84227d8",
      "metadata": {
        "gather": {
          "logged": 1724229619770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f22ed7aa-4e48-4488-b80c-63a35e733b33",
      "metadata": {
        "gather": {
          "logged": 1724229620074
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "COMPLETION_TOKENS = 2000\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4o\", \n",
        "                      temperature=0.5, max_tokens=COMPLETION_TOKENS, \n",
        "                      streaming=True, callback_manager=cb_manager)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0e567215",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional, Type\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.callbacks.manager import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun\n",
        "from langchain_community.utilities import BingSearchAPIWrapper\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "class SearchInput(BaseModel):\n",
        "    query: str = Field(description=\"Should be a search query\")\n",
        "\n",
        "\n",
        "class MyBingSearch(BaseTool):\n",
        "    \"\"\"Tool for performing web searches using Bing Search API.\"\"\"\n",
        "\n",
        "    name: str = \"Searcher\"\n",
        "    description: str = \"Useful to search the internet for real-time information.\"\n",
        "    args_schema: Type[BaseModel] = SearchInput\n",
        "    k: int = 5  # Number of results\n",
        "\n",
        "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        return bing.results(query, num_results=self.k)\n",
        "\n",
        "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        loop = asyncio.get_event_loop()\n",
        "        results = await loop.run_in_executor(ThreadPoolExecutor(), bing.results, query, self.k)\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f3a9dd6f-0762-40a9-b212-a9f7138ab64b",
      "metadata": {
        "gather": {
          "logged": 1724229627664
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def parse_html(content) -> str:\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "    text_content_with_links = soup.get_text()\n",
        "    return text_content_with_links\n",
        "\n",
        "def fetch_web_page(url: str) -> str:\n",
        "    HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0'}\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    return parse_html(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2d9d6efb-ee00-4271-9282-1a513185dd1e",
      "metadata": {
        "gather": {
          "logged": 1724229627805
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "web_fetch_tool = Tool.from_function(\n",
        "    func=fetch_web_page,\n",
        "    name=\"WebFetcher\",\n",
        "    description=\"useful to fetch the content of a url\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "23aab0bd-11f2-4318-8e10-33469e37c945",
      "metadata": {
        "gather": {
          "logged": 1724229629791
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# tools = [MyBingSearch(k=5), web_fetch_tool] # With GPT-4 you can add the web_fetch_tool\n",
        "\n",
        "tools = [MyBingSearch(k=5)] # With GPT-3.5 \n",
        "\n",
        "prompt = BINGSEARCH_PROMPT\n",
        "\n",
        "# Construct the OpenAI Tools agent\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, \n",
        "                               return_intermediate_steps=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e0bc94fb-85d1-444c-9097-6fce420b4e85",
      "metadata": {
        "gather": {
          "logged": 1724229641704
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[MyBingSearch()]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "890b4270-834a-499d-907c-c4396de4bc99",
      "metadata": {
        "gather": {
          "logged": 1724229643667
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# QUESTION = \"Create a list with the main facts on What is happening with the oil supply in the world right now?\"\n",
        "# QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "# QUESTION = \"My son needs to build a pinewood car for a pinewood derbi, how do I build such a car?\"\n",
        "# QUESTION = \"I'm planning a vacation to Greece, tell me budget for a family of 4, in Summer, for 7 days including travel, lodging and food costs\"\n",
        "# QUESTION = \"Who won the 2023 superbowl and who was the MVP?\"\n",
        "QUESTION = \"\"\"\n",
        "compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
        "\n",
        "- ADN Registerd Nurse \n",
        "- Occupational therapist assistant\n",
        "- Dental Hygienist\n",
        "- Graphic Designer\n",
        "\n",
        "\n",
        "# Create a table with your findings. Place the sources on each cell.\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "384faabb-2de3-4283-98f8-e1d828987114",
      "metadata": {
        "gather": {
          "logged": 1724229671695
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd531cb-a5dc-47e4-ae73-f7c83282a52d",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Without showing the intermedite steps, just the final answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "629d26b3-00f3-41dd-8576-84b18a48b381",
      "metadata": {
        "gather": {
          "logged": 1724229681702
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the current exchange rate, 50 USD is approximately equal to 45.63 Euros [[1]](https://wise.com/gb/currency-converter/usd-to-eur-rate?amount=50.99). \n",
            "\n",
            "Regarding the cost of an average hotel in Madrid, the price for a week's stay is surprisingly affordable at $625 on average, which equates to roughly $89 per night [[2]](https://www.budgetyourtrip.com/hotels/spain/madrid-3117735). In Euros, considering the current exchange rate, this would be approximately 80.72 Euros per night. \n",
            "\n",
            "Therefore, 50 USD converted to Euros (approximately 45.63 Euros) would not be enough for an average hotel night in Madrid, as the cost is closer to 80.72 Euros per night."
          ]
        }
      ],
      "source": [
        "QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "\n",
        "try:\n",
        "    response = agent_executor.invoke({\"question\":QUESTION})\n",
        "except Exception as e:\n",
        "    response = str(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8786a3ad-430e-4abc-8751-c38d8fe3716d",
      "metadata": {
        "gather": {
          "logged": 1724229681845
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the current exchange rate, 50 USD is approximately equal to 45.63 Euros [[1]](https://wise.com/gb/currency-converter/usd-to-eur-rate?amount=50.99). \n",
              "\n",
              "Regarding the cost of an average hotel in Madrid, the price for a week's stay is surprisingly affordable at USD 625 on average, which equates to roughly USD 89 per night [[2]](https://www.budgetyourtrip.com/hotels/spain/madrid-3117735). In Euros, considering the current exchange rate, this would be approximately 80.72 Euros per night. \n",
              "\n",
              "Therefore, 50 USD converted to Euros (approximately 45.63 Euros) would not be enough for an average hotel night in Madrid, as the cost is closer to 80.72 Euros per night."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "printmd(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58848313-e475-4e07-aa20-5b58dbb73676",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## QnA to specific websites\n",
        "\n",
        "There are several use cases where we want the smart bot to answer questions about a specific company's public website. There are two approaches we can take:\n",
        "\n",
        "1. Create a crawler script that runs regularly, finds every page on the website, and pushes the documents to Azure Cognitive Search.\n",
        "2. Since Bing has likely already indexed the public website, we can utilize Bing search targeted specifically to that site, rather than attempting to index the site ourselves and duplicate the work already done by Bing's crawler.\n",
        "\n",
        "Below are some sample questions related to specific sites. Take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "80631275-d9e4-49b6-b786-fdb6e94723db",
      "metadata": {
        "gather": {
          "logged": 1724229685666
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# QUESTION = \"information on how to kill wasps in homedepot.com\"\n",
        "QUESTION = \"in target.com, find how what's the price of a Nesspresso coffee machine and of a Keurig coffee machine\"\n",
        "# QUESTION = \"in microsoft.com, find out what is the latests news on quantum computing\"\n",
        "# QUESTION = \"give me on a list the main points on the latest investor report from mondelezinternational.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8da312eb-316f-4c76-a52b-eb8fafc178e3",
      "metadata": {
        "gather": {
          "logged": 1724229695668
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling Tool: `Searcher` with input `{'query': 'site:target.com Nespresso coffee machine price'}`\n",
            "---\n",
            "Calling Tool: `Searcher` with input `{'query': 'site:target.com Keurig coffee machine price'}`\n",
            "---\n",
            "Calling Tool: `WebFetcher` with input `{'url': 'https://www.target.com/p/nespresso-vertuo-next-coffee-maker-and-espresso-machine-by-delonghi-gray/-/A-79332989'}`\n",
            "---\n",
            "Calling Tool: `WebFetcher` with input `{'url': 'https://www.target.com/p/keurig-k-mini-single-serve-k-cup-pod-coffee-maker/-/A-53788870'}`\n",
            "---\n",
            "I encountered an issue accessing the specific product pages on Target's website to provide you with the current prices for the Nespresso and Keurig coffee machines. To find the most accurate and up-to-date prices, I recommend visiting Target's website directly and searching for the Nespresso and Keurig coffee machines. This will allow you to view the range of models available and their respective prices."
          ]
        }
      ],
      "source": [
        "async for chunk in agent_executor.astream({\"question\": QUESTION}):\n",
        "    # Agent Action\n",
        "    if \"actions\" in chunk:\n",
        "        for action in chunk[\"actions\"]:\n",
        "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
        "    # Observation\n",
        "    elif \"steps\" in chunk:\n",
        "        # Uncomment if you need to have the information retrieve from the tool\n",
        "        # for step in chunk[\"steps\"]:\n",
        "        #     print(f\"Tool Result: `{step.observation}`\")\n",
        "        continue\n",
        "    # Final result\n",
        "    elif \"output\" in chunk:\n",
        "        # No need to print the final output again since we would be streaming it as it is produced\n",
        "        # print(f'Final Output: {chunk[\"output\"]}') \n",
        "        continue\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e7ac1e-78bc-465d-89a1-5d9abbad90c9",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
